<!DOCTYPE HTML>
<html lang="en" >
    
    <head>
        
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <title>Solutions | An Introduction to Statistical Learning:</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 2.2.0">
        
        
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
        <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">
        
    <link rel="stylesheet" href="../gitbook/style.css">
    
    
        <link rel="stylesheet" href="../styles/website.css">
    

        
    
    
    <link rel="next" href="../chapter7/index.html" />
    
    
    <link rel="prev" href="../chapter6/lab.html" />
    

        
    </head>
    <body>
        
        
    <div class="book" data-level="5.2" data-basepath=".." data-revision="Wed Aug 19 2015 19:44:06 GMT+0100 (BST)">
    

<div class="book-summary">
    <div class="book-search">
        <input type="text" placeholder="Type to search" class="form-control" />
    </div>
    <ul class="summary">
        
        
        
        

        

        
    
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="../index.html">
                
                        <i class="fa fa-check"></i>
                        
                        Introduction
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1" data-path="chapter2/index.html">
            
                
                    <a href="../chapter2/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                        Chapter 2. Statistical Learning
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1" data-path="chapter2/lab.html">
            
                
                    <a href="../chapter2/lab.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.</b>
                        
                        Lab
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="chapter2/solutions.html">
            
                
                    <a href="../chapter2/solutions.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.</b>
                        
                        Solutions
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2" data-path="chapter3/index.html">
            
                
                    <a href="../chapter3/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.</b>
                        
                        Chapter 3. Linear Regression
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1" data-path="chapter3/lab.html">
            
                
                    <a href="../chapter3/lab.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.</b>
                        
                        Lab
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="chapter3/solutions.html">
            
                
                    <a href="../chapter3/solutions.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.</b>
                        
                        Solutions
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3" data-path="chapter4/index.html">
            
                
                    <a href="../chapter4/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.</b>
                        
                        Chapter 4. Classification
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1" data-path="chapter4/lab.html">
            
                
                    <a href="../chapter4/lab.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.</b>
                        
                        Lab
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="chapter4/solutions.html">
            
                
                    <a href="../chapter4/solutions.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.</b>
                        
                        Solutions
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4" data-path="chapter5/index.html">
            
                
                    <a href="../chapter5/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.</b>
                        
                        Chapter 5. Resampling Methods
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.1" data-path="chapter5/lab.html">
            
                
                    <a href="../chapter5/lab.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.1.</b>
                        
                        Lab
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="chapter5/solutions.html">
            
                
                    <a href="../chapter5/solutions.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.2.</b>
                        
                        Solutions
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="5" data-path="chapter6/index.html">
            
                
                    <a href="../chapter6/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.</b>
                        
                        Chapter 6. Linear Model Selection and Regularization
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="5.1" data-path="chapter6/lab.html">
            
                
                    <a href="../chapter6/lab.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.1.</b>
                        
                        Lab
                    </a>
            
            
        </li>
    
        <li class="chapter active" data-level="5.2" data-path="chapter6/solutions.html">
            
                
                    <a href="../chapter6/solutions.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.2.</b>
                        
                        Solutions
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="6" data-path="chapter7/index.html">
            
                
                    <a href="../chapter7/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.</b>
                        
                        Chapter 7. Moving Beyond Linearity
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="6.1" data-path="chapter7/lab.html">
            
                
                    <a href="../chapter7/lab.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.1.</b>
                        
                        Lab
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.2" data-path="chapter7/solutions.html">
            
                
                    <a href="../chapter7/solutions.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.2.</b>
                        
                        Solutions
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="7" data-path="chapter8/index.html">
            
                
                    <a href="../chapter8/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.</b>
                        
                        Chapter 8. Tree-Based Methods
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="7.1" data-path="chapter8/lab.html">
            
                
                    <a href="../chapter8/lab.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.1.</b>
                        
                        Lab
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.2" data-path="chapter8/solutions.html">
            
                
                    <a href="../chapter8/solutions.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.2.</b>
                        
                        Solutions
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="8" data-path="chapter9/index.html">
            
                
                    <a href="../chapter9/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.</b>
                        
                        Chapter 9. Support Vector Machines
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="8.1" data-path="chapter9/lab.html">
            
                
                    <a href="../chapter9/lab.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.1.</b>
                        
                        Lab
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="8.2" data-path="chapter9/solutions.html">
            
                
                    <a href="../chapter9/solutions.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.2.</b>
                        
                        Solutions
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="9" data-path="chapter10/index.html">
            
                
                    <a href="../chapter10/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.</b>
                        
                        Chapter 10. Unsupervised Learning
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="9.1" data-path="chapter10/lab.html">
            
                
                    <a href="../chapter10/lab.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.1.</b>
                        
                        Lab
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9.2" data-path="chapter10/solutions.html">
            
                
                    <a href="../chapter10/solutions.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.2.</b>
                        
                        Solutions
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="10" data-path="references.html">
            
                
                    <a href="../references.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.</b>
                        
                        References
                    </a>
            
            
        </li>
    


        
        <li class="divider"></li>
        <li>
            <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
                Published with GitBook
            </a>
        </li>
        
    </ul>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="book-header">
    <!-- Actions Left -->
    <a href="#" class="btn pull-left toggle-summary" aria-label="Table of Contents"><i class="fa fa-align-justify"></i></a>
    <a href="#" class="btn pull-left toggle-search" aria-label="Search"><i class="fa fa-search"></i></a>
    
    <div id="font-settings-wrapper" class="dropdown pull-left">
        <a href="#" class="btn toggle-dropdown" aria-label="Font Settings"><i class="fa fa-font"></i>
        </a>
        <div class="dropdown-menu font-settings">
    <div class="dropdown-caret">
        <span class="caret-outer"></span>
        <span class="caret-inner"></span>
    </div>

    <div class="buttons">
        <button type="button" id="reduce-font-size" class="button size-2">A</button>
        <button type="button" id="enlarge-font-size" class="button size-2">A</button>
    </div>

    <div class="buttons font-family-list">
        <button type="button" data-font="0" class="button">Serif</button>
        <button type="button" data-font="1" class="button">Sans</button>
    </div>

    <div class="buttons color-theme-list">
        <button type="button" id="color-theme-preview-0" class="button size-3" data-theme="0">White</button>
        <button type="button" id="color-theme-preview-1" class="button size-3" data-theme="1">Sepia</button>
        <button type="button" id="color-theme-preview-2" class="button size-3" data-theme="2">Night</button>
    </div>
</div>

    </div>

    <!-- Actions Right -->
    
    <div class="dropdown pull-right">
        <a href="#" class="btn toggle-dropdown" aria-label="Share"><i class="fa fa-share-alt"></i>
        </a>
        <div class="dropdown-menu font-settings dropdown-left">
            <div class="dropdown-caret">
                <span class="caret-outer"></span>
                <span class="caret-inner"></span>
            </div>
            <div class="buttons">
                <button type="button" data-sharing="twitter" class="button">
                    Share on Twitter
                </button>
                <button type="button" data-sharing="google-plus" class="button">
                    Share on Google
                </button>
                <button type="button" data-sharing="facebook" class="button">
                    Share on Facebook
                </button>
                <button type="button" data-sharing="weibo" class="button">
                    Share on Weibo
                </button>
                <button type="button" data-sharing="instapaper" class="button">
                    Share on Instapaper
                </button>
            </div>
        </div>
    </div>
    

    
    <a href="#" target="_blank" class="btn pull-right google-plus-sharing-link sharing-link" data-sharing="google-plus" aria-label="Google"><i class="fa fa-google-plus"></i></a>
    
    
    <a href="#" target="_blank" class="btn pull-right facebook-sharing-link sharing-link" data-sharing="facebook" aria-label="Facebook"><i class="fa fa-facebook"></i></a>
    
    
    <a href="#" target="_blank" class="btn pull-right twitter-sharing-link sharing-link" data-sharing="twitter" aria-label="Twitter"><i class="fa fa-twitter"></i></a>
    
    
    


    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../" >An Introduction to Statistical Learning:</a>
    </h1>
</div>

            <div class="page-wrapper" tabindex="-1">
                <div class="page-inner">
                
                
                    <section class="normal" id="section-">
                    
                        <h2 id="6-8-exercises">6.8 Exercises</h2>
<h3 id="exercise-8">Exercise 8</h3>
<pre><code class="lang-r"><span class="hljs-keyword">library</span>(<span class="hljs-string">&quot;ISLR&quot;</span>)
<span class="hljs-keyword">library</span>(<span class="hljs-string">&quot;leaps&quot;</span>)
<span class="hljs-keyword">library</span>(<span class="hljs-string">&quot;glmnet&quot;</span>)
</code></pre>
<pre><code>## Loading required package: Matrix
## Loading required package: foreach
## Loaded glmnet 2.0-2
</code></pre><pre><code class="lang-r">set.seed(<span class="hljs-number">0</span>)

n &lt;- <span class="hljs-number">100</span>
X &lt;- rnorm(n)
epsilon &lt;- <span class="hljs-number">0.1</span> * rnorm(n)

beta_0 &lt;- <span class="hljs-number">1</span>
beta_1 &lt;- -<span class="hljs-number">0.1</span>
beta_2 &lt;- +<span class="hljs-number">0.05</span>
beta_3 &lt;- <span class="hljs-number">0.75</span>

Y &lt;- beta_0 + beta_1 * X + beta_2 * X^<span class="hljs-number">2</span> + beta_3 * X^<span class="hljs-number">3</span> + epsilon

DF &lt;- data.frame(Y = Y, X = X, X2 = X^<span class="hljs-number">2</span>, X3 = X^<span class="hljs-number">3</span>, X4 = X^<span class="hljs-number">4</span>, X5 = X^<span class="hljs-number">5</span>, X6 = X^<span class="hljs-number">6</span>, X7 = X^<span class="hljs-number">7</span>, X8 = X^<span class="hljs-number">8</span>, X9 = X^<span class="hljs-number">9</span>, X10 = X^<span class="hljs-number">10</span>)

<span class="hljs-comment"># Use the validation approach with regsubsets</span>
train &lt;- sample(c(<span class="hljs-literal">TRUE</span>, <span class="hljs-literal">FALSE</span>), n, rep = <span class="hljs-literal">TRUE</span>)  <span class="hljs-comment"># will roughly assign TRUE to one-half of the data (FALSE to the other half).</span>
test &lt;- (!train)


<span class="hljs-comment"># -- Apply best subset selection: --</span>
regfit.full &lt;- regsubsets(Y ~ ., data = DF[train, ], nvmax = <span class="hljs-number">10</span>)
print(summary(regfit.full))
</code></pre>
<pre><code>## Subset selection object
## Call: regsubsets.formula(Y ~ ., data = DF[train, ], nvmax = 10)
## 10 Variables  (and intercept)
##     Forced in Forced out
## X       FALSE      FALSE
## X2      FALSE      FALSE
## X3      FALSE      FALSE
## X4      FALSE      FALSE
## X5      FALSE      FALSE
## X6      FALSE      FALSE
## X7      FALSE      FALSE
## X8      FALSE      FALSE
## X9      FALSE      FALSE
## X10     FALSE      FALSE
## 1 subsets of each size up to 10
## Selection Algorithm: exhaustive
##           X   X2  X3  X4  X5  X6  X7  X8  X9  X10
## 1  ( 1 )  &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;
## 2  ( 1 )  &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;
## 3  ( 1 )  &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;
## 4  ( 1 )  &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot;
## 5  ( 1 )  &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot;
## 6  ( 1 )  &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot;
## 7  ( 1 )  &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot;
## 8  ( 1 )  &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot;
## 9  ( 1 )  &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot;
## 10  ( 1 ) &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot;
</code></pre><pre><code class="lang-r">reg.summary &lt;- summary(regfit.full)

<span class="hljs-comment"># Test models on the validation set:</span>
test.mat &lt;- model.matrix(Y ~ ., data = DF[test, ])
val.errors &lt;- rep(<span class="hljs-literal">NA</span>, <span class="hljs-number">10</span>)
<span class="hljs-keyword">for</span> (ii <span class="hljs-keyword">in</span> <span class="hljs-number">1</span>:<span class="hljs-number">10</span>) {
    coefi &lt;- coef(regfit.full, id = ii)
    pred &lt;- test.mat[, names(coefi)] %*% coefi
    val.errors[ii] &lt;- mean((DF$Y[test] - pred)^<span class="hljs-number">2</span>)
}
print(<span class="hljs-string">&quot;best subset validation errors&quot;</span>)
</code></pre>
<pre><code>## [1] &quot;best subset validation errors&quot;
</code></pre><pre><code class="lang-r">print(val.errors)
</code></pre>
<pre><code>##  [1] 0.015567409 0.013245221 0.009026844 0.017169840 0.065102301
##  [6] 5.962097578 5.599171828 0.010197576 0.328677632 0.055217617
</code></pre><pre><code class="lang-r">k &lt;- which.min(val.errors)
print(k)
</code></pre>
<pre><code>## [1] 3
</code></pre><pre><code class="lang-r">print(coef(regfit.full, id = k))
</code></pre>
<pre><code>## (Intercept)           X          X2          X3 
##  1.01506706 -0.11855671  0.02753875  0.76721123
</code></pre><pre><code class="lang-r">old.par &lt;- par(mfrow = c(<span class="hljs-number">1</span>, <span class="hljs-number">4</span>))
<span class="hljs-comment"># plot( reg.summary$rss, xlab=&apos;Number of variables&apos;, ylab=&apos;RSS&apos; )</span>
plot(reg.summary$cp, xlab = <span class="hljs-string">&quot;Number of variables&quot;</span>, ylab = <span class="hljs-string">&quot;Cp&quot;</span>, pch = <span class="hljs-number">19</span>)
plot(reg.summary$bic, xlab = <span class="hljs-string">&quot;Number of variables&quot;</span>, ylab = <span class="hljs-string">&quot;BIC&quot;</span>, pch = <span class="hljs-number">19</span>)
plot(reg.summary$adjr2, xlab = <span class="hljs-string">&quot;Number of variables&quot;</span>, ylab = <span class="hljs-string">&quot;adjusted R2&quot;</span>, pch = <span class="hljs-number">19</span>)

plot(val.errors, xlab = <span class="hljs-string">&quot;Number of variables&quot;</span>, ylab = <span class="hljs-string">&quot;Validation Errors&quot;</span>, pch = <span class="hljs-number">19</span>)
</code></pre>
<p><img src="solutions_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-1-1.png" alt=""></p>
<pre><code class="lang-r">par(mfrow = c(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))

<span class="hljs-comment"># -- Now apply foward selection on the training set: --</span>
regfit.forward &lt;- regsubsets(Y ~ ., data = DF[train, ], nvmax = <span class="hljs-number">10</span>, method = <span class="hljs-string">&quot;forward&quot;</span>)
print(summary(regfit.forward))
</code></pre>
<pre><code>## Subset selection object
## Call: regsubsets.formula(Y ~ ., data = DF[train, ], nvmax = 10, method = &quot;forward&quot;)
## 10 Variables  (and intercept)
##     Forced in Forced out
## X       FALSE      FALSE
## X2      FALSE      FALSE
## X3      FALSE      FALSE
## X4      FALSE      FALSE
## X5      FALSE      FALSE
## X6      FALSE      FALSE
## X7      FALSE      FALSE
## X8      FALSE      FALSE
## X9      FALSE      FALSE
## X10     FALSE      FALSE
## 1 subsets of each size up to 10
## Selection Algorithm: forward
##           X   X2  X3  X4  X5  X6  X7  X8  X9  X10
## 1  ( 1 )  &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;
## 2  ( 1 )  &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;
## 3  ( 1 )  &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;
## 4  ( 1 )  &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;
## 5  ( 1 )  &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;
## 6  ( 1 )  &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot;
## 7  ( 1 )  &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot;
## 8  ( 1 )  &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot;
## 9  ( 1 )  &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot;
## 10  ( 1 ) &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot;
</code></pre><pre><code class="lang-r">reg.summary &lt;- summary(regfit.forward)

<span class="hljs-comment"># Test models on the validation set:</span>
test.mat &lt;- model.matrix(Y ~ ., data = DF[test, ])
val.errors &lt;- rep(<span class="hljs-literal">NA</span>, <span class="hljs-number">10</span>)
<span class="hljs-keyword">for</span> (ii <span class="hljs-keyword">in</span> <span class="hljs-number">1</span>:<span class="hljs-number">10</span>) {
    coefi &lt;- coef(regfit.forward, id = ii)
    pred &lt;- test.mat[, names(coefi)] %*% coefi
    val.errors[ii] &lt;- mean((DF$Y[test] - pred)^<span class="hljs-number">2</span>)
}
print(<span class="hljs-string">&quot;forward selection validation errors&quot;</span>)
</code></pre>
<pre><code>## [1] &quot;forward selection validation errors&quot;
</code></pre><pre><code class="lang-r">print(val.errors)
</code></pre>
<pre><code>##  [1] 0.015567409 0.013245221 0.009026844 0.014540813 0.055005227
##  [6] 0.049894349 1.525498490 4.476027607 3.997884857 0.055217617
</code></pre><pre><code class="lang-r">k &lt;- which.min(val.errors)
print(k)
</code></pre>
<pre><code>## [1] 3
</code></pre><pre><code class="lang-r">print(coef(regfit.forward, id = k))
</code></pre>
<pre><code>## (Intercept)           X          X2          X3 
##  1.01506706 -0.11855671  0.02753875  0.76721123
</code></pre><pre><code class="lang-r">old.par &lt;- par(mfrow = c(<span class="hljs-number">1</span>, <span class="hljs-number">4</span>))
<span class="hljs-comment"># plot( reg.summary$rss, xlab=&apos;Number of variables&apos;, ylab=&apos;RSS&apos; )</span>
plot(reg.summary$cp, xlab = <span class="hljs-string">&quot;Number of variables&quot;</span>, ylab = <span class="hljs-string">&quot;Cp&quot;</span>, pch = <span class="hljs-number">19</span>)
plot(reg.summary$bic, xlab = <span class="hljs-string">&quot;Number of variables&quot;</span>, ylab = <span class="hljs-string">&quot;BIC&quot;</span>, pch = <span class="hljs-number">19</span>)
plot(reg.summary$adjr2, xlab = <span class="hljs-string">&quot;Number of variables&quot;</span>, ylab = <span class="hljs-string">&quot;adjusted R2&quot;</span>, pch = <span class="hljs-number">19</span>)

plot(val.errors, xlab = <span class="hljs-string">&quot;Number of variables&quot;</span>, ylab = <span class="hljs-string">&quot;Validation Errors&quot;</span>, pch = <span class="hljs-number">19</span>)
</code></pre>
<p><img src="solutions_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-1-2.png" alt=""></p>
<pre><code class="lang-r">par(mfrow = c(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))


<span class="hljs-comment"># -- Now apply backwards selection to the training set: --</span>
regfit.backward &lt;- regsubsets(Y ~ ., data = DF[train, ], nvmax = <span class="hljs-number">10</span>, method = <span class="hljs-string">&quot;backward&quot;</span>)
print(summary(regfit.backward))
</code></pre>
<pre><code>## Subset selection object
## Call: regsubsets.formula(Y ~ ., data = DF[train, ], nvmax = 10, method = &quot;backward&quot;)
## 10 Variables  (and intercept)
##     Forced in Forced out
## X       FALSE      FALSE
## X2      FALSE      FALSE
## X3      FALSE      FALSE
## X4      FALSE      FALSE
## X5      FALSE      FALSE
## X6      FALSE      FALSE
## X7      FALSE      FALSE
## X8      FALSE      FALSE
## X9      FALSE      FALSE
## X10     FALSE      FALSE
## 1 subsets of each size up to 10
## Selection Algorithm: backward
##           X   X2  X3  X4  X5  X6  X7  X8  X9  X10
## 1  ( 1 )  &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;
## 2  ( 1 )  &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;
## 3  ( 1 )  &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;
## 4  ( 1 )  &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot;
## 5  ( 1 )  &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot;
## 6  ( 1 )  &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot;
## 7  ( 1 )  &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot;
## 8  ( 1 )  &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot;
## 9  ( 1 )  &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot;
## 10  ( 1 ) &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot;
</code></pre><pre><code class="lang-r">reg.summary &lt;- summary(regfit.backward)

<span class="hljs-comment"># Test models on the validation set:</span>
test.mat &lt;- model.matrix(Y ~ ., data = DF[test, ])
val.errors &lt;- rep(<span class="hljs-literal">NA</span>, <span class="hljs-number">10</span>)
<span class="hljs-keyword">for</span> (ii <span class="hljs-keyword">in</span> <span class="hljs-number">1</span>:<span class="hljs-number">10</span>) {
    coefi &lt;- coef(regfit.backward, id = ii)
    pred &lt;- test.mat[, names(coefi)] %*% coefi
    val.errors[ii] &lt;- mean((DF$Y[test] - pred)^<span class="hljs-number">2</span>)
}
print(<span class="hljs-string">&quot;backwards selection validation errors&quot;</span>)
</code></pre>
<pre><code>## [1] &quot;backwards selection validation errors&quot;
</code></pre><pre><code class="lang-r">print(val.errors)
</code></pre>
<pre><code>##  [1] 0.015567409 0.011250512 0.009026844 0.017169840 0.069259376
##  [6] 0.546418670 2.799471622 0.010197576 0.328677632 0.055217617
</code></pre><pre><code class="lang-r">k &lt;- which.min(val.errors)
print(k)
</code></pre>
<pre><code>## [1] 3
</code></pre><pre><code class="lang-r">print(coef(regfit.backward, id = k))
</code></pre>
<pre><code>## (Intercept)           X          X2          X3 
##  1.01506706 -0.11855671  0.02753875  0.76721123
</code></pre><pre><code class="lang-r">old.par &lt;- par(mfrow = c(<span class="hljs-number">1</span>, <span class="hljs-number">4</span>))
<span class="hljs-comment"># plot( reg.summary$rss, xlab=&apos;Number of variables&apos;, ylab=&apos;RSS&apos; )</span>
plot(reg.summary$cp, xlab = <span class="hljs-string">&quot;Number of variables&quot;</span>, ylab = <span class="hljs-string">&quot;Cp&quot;</span>, pch = <span class="hljs-number">19</span>)
plot(reg.summary$bic, xlab = <span class="hljs-string">&quot;Number of variables&quot;</span>, ylab = <span class="hljs-string">&quot;BIC&quot;</span>, pch = <span class="hljs-number">19</span>)
plot(reg.summary$adjr2, xlab = <span class="hljs-string">&quot;Number of variables&quot;</span>, ylab = <span class="hljs-string">&quot;adjusted R2&quot;</span>, pch = <span class="hljs-number">19</span>)

plot(val.errors, xlab = <span class="hljs-string">&quot;Number of variables&quot;</span>, ylab = <span class="hljs-string">&quot;Validation Errors&quot;</span>, pch = <span class="hljs-number">19</span>)
</code></pre>
<p><img src="solutions_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-1-3.png" alt=""></p>
<pre><code class="lang-r">par(mfrow = c(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))


<span class="hljs-comment"># -- Now apply the lasso to our training set: --</span>

<span class="hljs-comment"># First fit the lasso model for all of the given lambda values :</span>
grid &lt;- <span class="hljs-number">10</span>^seq(<span class="hljs-number">10</span>, -<span class="hljs-number">2</span>, length = <span class="hljs-number">100</span>)  <span class="hljs-comment"># a grid of lambda values </span>
Y &lt;- DF$Y
MM &lt;- model.matrix(Y ~ ., data = DF)  <span class="hljs-comment"># the predictors as a datamatrix </span>
lasso.mod &lt;- glmnet(MM, Y, alpha = <span class="hljs-number">1</span>, lambda = grid)
plot(lasso.mod)  <span class="hljs-comment"># plots the extracted coefficients as a function of lambda</span>
</code></pre>
<p><img src="solutions_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-1-4.png" alt=""></p>
<pre><code class="lang-r"><span class="hljs-comment"># Apply cross validation (to pick the best value of lambda):</span>
cv.out &lt;- cv.glmnet(MM, Y, alpha = <span class="hljs-number">1</span>)
bestlam &lt;- cv.out$lambda.1se
print(<span class="hljs-string">&quot;lasso CV best value of lambda (one standard error)&quot;</span>)
</code></pre>
<pre><code>## [1] &quot;lasso CV best value of lambda (one standard error)&quot;
</code></pre><pre><code class="lang-r">print(bestlam)
</code></pre>
<pre><code>## [1] 0.03186245
</code></pre><pre><code class="lang-r">plot(cv.out)
</code></pre>
<p><img src="solutions_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-1-5.png" alt=""></p>
<pre><code class="lang-r"><span class="hljs-comment"># Extract the optimal coefficients used:</span>
lasso.coef &lt;- predict(lasso.mod, type = <span class="hljs-string">&quot;coefficients&quot;</span>, s = bestlam)
print(lasso.coef)
</code></pre>
<pre><code>## 12 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                       1
## (Intercept) 1.026020037
## (Intercept) .          
## X           .          
## X2          0.004179690
## X3          0.664868098
## X4          0.003606719
## X5          0.011344145
## X6          .          
## X7          .          
## X8          .          
## X9          .          
## X10         .
</code></pre><pre><code class="lang-r"><span class="hljs-comment"># Part (f) Try a different regression function:</span>
X &lt;- rnorm(n)
epsilon &lt;- <span class="hljs-number">0.1</span> * rnorm(n)

beta_0 &lt;- <span class="hljs-number">1</span>
beta_7 &lt;- <span class="hljs-number">2.5</span>
Y &lt;- beta_0 + beta_7 * X^<span class="hljs-number">7</span> + epsilon
DF &lt;- data.frame(Y = Y, X = X, X2 = X^<span class="hljs-number">2</span>, X3 = X^<span class="hljs-number">3</span>, X4 = X^<span class="hljs-number">4</span>, X5 = X^<span class="hljs-number">5</span>, X6 = X^<span class="hljs-number">6</span>, X7 = X^<span class="hljs-number">7</span>, X8 = X^<span class="hljs-number">8</span>, X9 = X^<span class="hljs-number">9</span>, X10 = X^<span class="hljs-number">10</span>)

train &lt;- sample(c(<span class="hljs-literal">TRUE</span>, <span class="hljs-literal">FALSE</span>), n, rep = <span class="hljs-literal">TRUE</span>)  <span class="hljs-comment"># will roughly assign TRUE to one-half of the data (FALSE to the other half).</span>
test &lt;- (!train)

<span class="hljs-comment"># Best subset selection:</span>
regfit.full &lt;- regsubsets(Y ~ ., data = DF[train, ], nvmax = <span class="hljs-number">10</span>)
print(summary(regfit.full))
</code></pre>
<pre><code>## Subset selection object
## Call: regsubsets.formula(Y ~ ., data = DF[train, ], nvmax = 10)
## 10 Variables  (and intercept)
##     Forced in Forced out
## X       FALSE      FALSE
## X2      FALSE      FALSE
## X3      FALSE      FALSE
## X4      FALSE      FALSE
## X5      FALSE      FALSE
## X6      FALSE      FALSE
## X7      FALSE      FALSE
## X8      FALSE      FALSE
## X9      FALSE      FALSE
## X10     FALSE      FALSE
## 1 subsets of each size up to 10
## Selection Algorithm: exhaustive
##           X   X2  X3  X4  X5  X6  X7  X8  X9  X10
## 1  ( 1 )  &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot;
## 2  ( 1 )  &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot;
## 3  ( 1 )  &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot;
## 4  ( 1 )  &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot;
## 5  ( 1 )  &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot;
## 6  ( 1 )  &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot;
## 7  ( 1 )  &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot;
## 8  ( 1 )  &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot;
## 9  ( 1 )  &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot;
## 10  ( 1 ) &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot;
</code></pre><pre><code class="lang-r"><span class="hljs-comment"># Test best subset models on the validation set:</span>
test.mat &lt;- model.matrix(Y ~ ., data = DF[test, ])
val.errors &lt;- rep(<span class="hljs-literal">NA</span>, <span class="hljs-number">10</span>)
<span class="hljs-keyword">for</span> (ii <span class="hljs-keyword">in</span> <span class="hljs-number">1</span>:<span class="hljs-number">10</span>) {
    coefi &lt;- coef(regfit.full, id = ii)
    pred &lt;- test.mat[, names(coefi)] %*% coefi
    val.errors[ii] &lt;- mean((DF$Y[test] - pred)^<span class="hljs-number">2</span>)
}
print(<span class="hljs-string">&quot;best subsets validation errors&quot;</span>)
</code></pre>
<pre><code>## [1] &quot;best subsets validation errors&quot;
</code></pre><pre><code class="lang-r">print(val.errors)
</code></pre>
<pre><code>##  [1] 0.01151953 0.01334971 0.01514501 0.06420174 0.09905791 1.86716273
##  [7] 0.62617621 0.58059869 0.53819549 1.05507636
</code></pre><pre><code class="lang-r">k &lt;- which.min(val.errors)
print(k)
</code></pre>
<pre><code>## [1] 1
</code></pre><pre><code class="lang-r">print(<span class="hljs-string">&quot;best subsets optimal coefficients&quot;</span>)
</code></pre>
<pre><code>## [1] &quot;best subsets optimal coefficients&quot;
</code></pre><pre><code class="lang-r">print(coef(regfit.full, id = k))  <span class="hljs-comment"># print the coefficients of the best model</span>
</code></pre>
<pre><code>## (Intercept)          X7 
##   0.9840339   2.5000261
</code></pre><pre><code class="lang-r">print(val.errors[k])
</code></pre>
<pre><code>## [1] 0.01151953
</code></pre><pre><code class="lang-r"><span class="hljs-comment"># Using the lasso technique:</span>

<span class="hljs-comment"># First apply cross validation (to find the optimal value of lambda):</span>
MM &lt;- model.matrix(Y ~ ., data = DF)

cv.out &lt;- cv.glmnet(MM, Y, alpha = <span class="hljs-number">1</span>)
plot(cv.out)
</code></pre>
<p><img src="solutions_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-1-6.png" alt=""></p>
<pre><code class="lang-r">bestlam &lt;- cv.out$lambda.1se
print(<span class="hljs-string">&quot;best lambda (1 se)&quot;</span>)
</code></pre>
<pre><code>## [1] &quot;best lambda (1 se)&quot;
</code></pre><pre><code class="lang-r">print(bestlam)
</code></pre>
<pre><code>## [1] 42.84324
</code></pre><pre><code class="lang-r"><span class="hljs-comment"># Now fit the lasso with this value of lambda:</span>
lasso.mod &lt;- glmnet(MM, Y, alpha = <span class="hljs-number">1</span>)

lasso.coef &lt;- predict(lasso.mod, type = <span class="hljs-string">&quot;coefficients&quot;</span>, s = bestlam)
print(<span class="hljs-string">&quot;lasso optimal coefficients&quot;</span>)
</code></pre>
<pre><code>## [1] &quot;lasso optimal coefficients&quot;
</code></pre><pre><code class="lang-r">print(lasso.coef)
</code></pre>
<pre><code>## 12 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                     1
## (Intercept) 5.3888292
## (Intercept) .        
## X           .        
## X2          .        
## X3          .        
## X4          .        
## X5          .        
## X6          0.2125842
## X7          2.3286883
## X8          .        
## X9          .        
## X10         .
</code></pre><pre><code class="lang-r">print(<span class="hljs-string">&quot;I do not think the predict method is working correctly...&quot;</span>)
</code></pre>
<pre><code>## [1] &quot;I do not think the predict method is working correctly...&quot;
</code></pre><pre><code class="lang-r">lasso.predict &lt;- predict(lasso.mod, s = bestlam, newx = MM)
print(<span class="hljs-string">&quot;lasso RSS error&quot;</span>)
</code></pre>
<pre><code>## [1] &quot;lasso RSS error&quot;
</code></pre><pre><code class="lang-r">print(mean((Y - lasso.predict)^<span class="hljs-number">2</span>))
</code></pre>
<pre><code>## [1] 1839.887
</code></pre><h3 id="exercise-9">Exercise 9</h3>
<pre><code class="lang-r"><span class="hljs-keyword">library</span>(pls)
</code></pre>
<pre><code>## 
## Attaching package: &apos;pls&apos;
## 
## The following object is masked from &apos;package:stats&apos;:
## 
##     loadings
</code></pre><pre><code class="lang-r">set.seed(<span class="hljs-number">0</span>)

n &lt;- dim(College)[<span class="hljs-number">1</span>]
p &lt;- dim(College)[<span class="hljs-number">2</span>]

train &lt;- sample(c(<span class="hljs-literal">TRUE</span>, <span class="hljs-literal">FALSE</span>), n, rep = <span class="hljs-literal">TRUE</span>)  <span class="hljs-comment"># will roughly assign TRUE to one-half of the data (FALSE to the other half).</span>
test &lt;- (!train)

College_train &lt;- College[train, ]
College_test &lt;- College[test, ]

<span class="hljs-comment"># Part (b):</span>
m &lt;- lm(Apps ~ ., data = College_train)

Y_hat &lt;- predict(m, newdata = College_test)
MSE &lt;- mean((College_test$Apps - Y_hat)^<span class="hljs-number">2</span>)
print(sprintf(<span class="hljs-string">&quot;Linear model test MSE= %10.3f&quot;</span>, MSE))
</code></pre>
<pre><code>## [1] &quot;Linear model test MSE= 1615966.966&quot;
</code></pre><pre><code class="lang-r"><span class="hljs-comment"># Part (c):</span>
Y &lt;- College_train$Apps
MM &lt;- model.matrix(Apps ~ ., data = College_train)
cv.out &lt;- cv.glmnet(MM, Y, alpha = <span class="hljs-number">0</span>)
plot(cv.out)
</code></pre>
<p><img src="solutions_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-2-1.png" alt=""></p>
<pre><code class="lang-r">bestlam &lt;- cv.out$lambda.1se
<span class="hljs-comment"># print( &apos;ridge regression CV best value of lambda (one standard error)&apos; ) print( bestlam )</span>

ridge.mod &lt;- glmnet(MM, Y, alpha = <span class="hljs-number">0</span>)

Y_hat &lt;- predict(ridge.mod, s = bestlam, newx = model.matrix(Apps ~ ., data = College_test))
MSE &lt;- mean((College_test$Apps - Y_hat)^<span class="hljs-number">2</span>)
print(sprintf(<span class="hljs-string">&quot;Ridge regression test MSE= %10.3f&quot;</span>, MSE))
</code></pre>
<pre><code>## [1] &quot;Ridge regression test MSE= 3318015.663&quot;
</code></pre><pre><code class="lang-r"><span class="hljs-comment"># Part (d):</span>
cv.out &lt;- cv.glmnet(MM, Y, alpha = <span class="hljs-number">1</span>)
plot(cv.out)
</code></pre>
<p><img src="solutions_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-2-2.png" alt=""></p>
<pre><code class="lang-r">bestlam &lt;- cv.out$lambda.1se
<span class="hljs-comment"># print( &apos;lasso CV best value of lambda (one standard error)&apos; ) print( bestlam )</span>

lasso.mod &lt;- glmnet(MM, Y, alpha = <span class="hljs-number">1</span>)

Y_hat &lt;- predict(lasso.mod, s = bestlam, newx = model.matrix(Apps ~ ., data = College_test))
MSE &lt;- mean((College_test$Apps - Y_hat)^<span class="hljs-number">2</span>)
print(sprintf(<span class="hljs-string">&quot;Lasso regression test MSE= %10.3f&quot;</span>, MSE))
</code></pre>
<pre><code>## [1] &quot;Lasso regression test MSE= 2018489.732&quot;
</code></pre><pre><code class="lang-r">print(<span class="hljs-string">&quot;lasso coefficients&quot;</span>)
</code></pre>
<pre><code>## [1] &quot;lasso coefficients&quot;
</code></pre><pre><code class="lang-r">print(predict(lasso.mod, type = <span class="hljs-string">&quot;coefficients&quot;</span>, s = bestlam))
</code></pre>
<pre><code>## 19 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                         1
## (Intercept) -515.67319420
## (Intercept)    .         
## PrivateYes     .         
## Accept         1.26431392
## Enroll         .         
## Top10perc     14.89903622
## Top25perc      .         
## F.Undergrad    0.01925533
## P.Undergrad    .         
## Outstate       .         
## Room.Board     .         
## Books          .         
## Personal       .         
## PhD            .         
## Terminal       .         
## S.F.Ratio      .         
## perc.alumni    .         
## Expend         0.04586867
## Grad.Rate      .
</code></pre><pre><code class="lang-r"><span class="hljs-comment"># Part (e):</span>
pcr.mod &lt;- pcr(Apps ~ ., data = College_train, scale = <span class="hljs-literal">TRUE</span>, validation = <span class="hljs-string">&quot;CV&quot;</span>)

<span class="hljs-comment"># Use this to select the number of components to include ... looks like CV suggests we should use ALL predictors</span>
validationplot(pcr.mod, val.type = <span class="hljs-string">&quot;MSEP&quot;</span>)
</code></pre>
<p><img src="solutions_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-2-3.png" alt=""></p>
<pre><code class="lang-r">ncomp &lt;- <span class="hljs-number">17</span>
Y_hat &lt;- predict(pcr.mod, College_test, ncomp = ncomp)
MSE &lt;- mean((College_test$Apps - Y_hat)^<span class="hljs-number">2</span>)
print(sprintf(<span class="hljs-string">&quot;PCR (with ncomp= %5d) test MSE= %10.3f&quot;</span>, ncomp, MSE))
</code></pre>
<pre><code>## [1] &quot;PCR (with ncomp=    17) test MSE= 1615966.966&quot;
</code></pre><pre><code class="lang-r"><span class="hljs-comment"># Part (f):</span>
pls.mod &lt;- plsr(Apps ~ ., data = College_train, scale = <span class="hljs-literal">TRUE</span>, validation = <span class="hljs-string">&quot;CV&quot;</span>)

<span class="hljs-comment"># Use this to select the number of components to include ... looks like CV suggests the best is to use ALL predictors but there is</span>
<span class="hljs-comment"># not much change in moving from ~ 5 predictors to 17 so we will take 10 (somewhere in the middle)</span>
validationplot(pls.mod, val.type = <span class="hljs-string">&quot;MSEP&quot;</span>)
</code></pre>
<p><img src="solutions_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-2-4.png" alt=""></p>
<pre><code class="lang-r">ncomp &lt;- <span class="hljs-number">10</span>
Y_hat &lt;- predict(pls.mod, College_test, ncomp = ncomp)
MSE &lt;- mean((College_test$Apps - Y_hat)^<span class="hljs-number">2</span>)
print(sprintf(<span class="hljs-string">&quot;PLS (with ncomp= %5d) test MSE= %10.3f&quot;</span>, ncomp, MSE))
</code></pre>
<pre><code>## [1] &quot;PLS (with ncomp=    10) test MSE= 1601425.747&quot;
</code></pre><h3 id="exercise-10">Exercise 10</h3>
<pre><code class="lang-r">set.seed(<span class="hljs-number">0</span>)

<span class="hljs-comment"># The sample size and the number of features:</span>
n &lt;- <span class="hljs-number">1000</span>
p &lt;- <span class="hljs-number">20</span>

<span class="hljs-comment"># Create the true value of beta (and zero out half of the entries):</span>
beta_truth &lt;- rnorm(p + <span class="hljs-number">1</span>)  <span class="hljs-comment"># add one for the constant beta_0 </span>
zero_locations &lt;- c(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">11</span>, <span class="hljs-number">12</span>, <span class="hljs-number">15</span>, <span class="hljs-number">17</span>, <span class="hljs-number">20</span>)
beta_truth[zero_locations] &lt;- <span class="hljs-number">0</span>
<span class="hljs-comment"># For debugging lets check that we can recover our coefficients: beta_truth = rep(0,p+1); beta_truth[1] = 1.5; beta_truth[10] = 3.5;</span>
<span class="hljs-comment"># beta_truth[15] = -3.4</span>
print(<span class="hljs-string">&quot;True values for beta (beta_0-beta_20):&quot;</span>)
</code></pre>
<pre><code>## [1] &quot;True values for beta (beta_0-beta_20):&quot;
</code></pre><pre><code class="lang-r">print(beta_truth)
</code></pre>
<pre><code>##  [1]  1.262954285  0.000000000  0.000000000  0.000000000  0.414641434
##  [6] -1.539950042  0.000000000  0.000000000 -0.005767173  2.404653389
## [11]  0.000000000  0.000000000 -1.147657009 -0.289461574  0.000000000
## [16] -0.411510833  0.000000000 -0.891921127  0.435683299  0.000000000
## [21] -0.224267885
</code></pre><pre><code class="lang-r"><span class="hljs-comment"># Generate some input features and an output response:</span>
X &lt;- c(rep(<span class="hljs-number">1</span>, n), rnorm(n * p))  <span class="hljs-comment"># make leading column of ones </span>
X &lt;- matrix(X, nrow = n, ncol = (p + <span class="hljs-number">1</span>), byrow = <span class="hljs-literal">FALSE</span>)

Y &lt;- X %*% beta_truth + rnorm(n)

<span class="hljs-comment"># Create a dataframe with this data:</span>
DF &lt;- data.frame(Y, X[, -<span class="hljs-number">1</span>])  <span class="hljs-comment"># drop the column of ones </span>

train_inds &lt;- sample(<span class="hljs-number">1</span>:n, <span class="hljs-number">100</span>)
test_inds &lt;- (<span class="hljs-number">1</span>:n)[-train_inds]

<span class="hljs-comment"># -- Apply best subset selection using the training data: --</span>
regfit.full &lt;- regsubsets(Y ~ ., data = DF[train_inds, ], nvmax = <span class="hljs-number">20</span>)
<span class="hljs-comment"># print( summary( regfit.full ) )</span>
reg.summary &lt;- summary(regfit.full)

<span class="hljs-comment"># Plot the in-sample MSE:</span>
training.mat &lt;- model.matrix(Y ~ ., data = DF[train_inds, ])
training.errors &lt;- rep(<span class="hljs-literal">NA</span>, <span class="hljs-number">20</span>)
<span class="hljs-keyword">for</span> (ii <span class="hljs-keyword">in</span> <span class="hljs-number">1</span>:<span class="hljs-number">20</span>) {
    coefi &lt;- coef(regfit.full, id = ii)
    pred &lt;- training.mat[, names(coefi)] %*% coefi
    training.errors[ii] &lt;- mean((DF$Y[train_inds] - pred)^<span class="hljs-number">2</span>)
}
print(<span class="hljs-string">&quot;best subset training MSE&quot;</span>)
</code></pre>
<pre><code>## [1] &quot;best subset training MSE&quot;
</code></pre><pre><code class="lang-r">print(training.errors)
</code></pre>
<pre><code>##  [1] 5.9770059 3.7871159 2.4678405 1.7251665 1.2576488 1.1772519 1.0768021
##  [8] 1.0087222 0.9721521 0.9530143 0.9304660 0.9254522 0.9206935 0.9152359
## [15] 0.9133050 0.9125718 0.9117938 0.9112271 0.9108313 0.9106024
</code></pre><pre><code class="lang-r">plot(<span class="hljs-number">1</span>:<span class="hljs-number">20</span>, training.errors, xlab = <span class="hljs-string">&quot;number of predictors&quot;</span>, ylab = <span class="hljs-string">&quot;training MSE&quot;</span>, type = <span class="hljs-string">&quot;o&quot;</span>, col = <span class="hljs-string">&quot;red&quot;</span>, ylim = c(<span class="hljs-number">0</span>, <span class="hljs-number">9</span>))

<span class="hljs-comment"># Test models on the validation set:</span>
test.mat &lt;- model.matrix(Y ~ ., data = DF[test_inds, ])
val.errors &lt;- rep(<span class="hljs-literal">NA</span>, <span class="hljs-number">20</span>)
<span class="hljs-keyword">for</span> (ii <span class="hljs-keyword">in</span> <span class="hljs-number">1</span>:<span class="hljs-number">20</span>) {
    coefi &lt;- coef(regfit.full, id = ii)
    pred &lt;- test.mat[, names(coefi)] %*% coefi
    val.errors[ii] &lt;- mean((DF$Y[test_inds] - pred)^<span class="hljs-number">2</span>)
}
print(<span class="hljs-string">&quot;best subset validation MSE&quot;</span>)
</code></pre>
<pre><code>## [1] &quot;best subset validation MSE&quot;
</code></pre><pre><code class="lang-r">print(val.errors)
</code></pre>
<pre><code>##  [1] 6.531306 3.895918 2.584956 1.787702 1.642511 1.458888 1.232284
##  [8] 1.111670 1.180321 1.214303 1.251878 1.267629 1.274193 1.293091
## [15] 1.290385 1.292731 1.290206 1.294843 1.295492 1.297954
</code></pre><pre><code class="lang-r">k &lt;- which.min(val.errors)
print(k)
</code></pre>
<pre><code>## [1] 8
</code></pre><pre><code class="lang-r">print(coef(regfit.full, id = k))
</code></pre>
<pre><code>## (Intercept)          X4          X5          X9         X12         X13 
##   1.3210455   0.4132288  -1.5880109   2.4639393  -1.1455077  -0.2815162 
##         X15         X17         X18 
##  -0.3589236  -1.0286318   0.6142240
</code></pre><pre><code class="lang-r">points(<span class="hljs-number">1</span>:<span class="hljs-number">20</span>, val.errors, xlab = <span class="hljs-string">&quot;number of predictors&quot;</span>, ylab = <span class="hljs-string">&quot;testing MSE&quot;</span>, type = <span class="hljs-string">&quot;o&quot;</span>, col = <span class="hljs-string">&quot;green&quot;</span>)

grid()
legend(<span class="hljs-number">11</span>, <span class="hljs-number">9.25</span>, c(<span class="hljs-string">&quot;Training MSE&quot;</span>, <span class="hljs-string">&quot;Testing MSE&quot;</span>), col = c(<span class="hljs-string">&quot;red&quot;</span>, <span class="hljs-string">&quot;green&quot;</span>), lty = c(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))
</code></pre>
<p><img src="solutions_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-3-1.png" alt=""></p>
<pre><code class="lang-r"><span class="hljs-comment"># Part (g):</span>
nms &lt;- colnames(DF)
nms[<span class="hljs-number">1</span>] &lt;- <span class="hljs-string">&quot;(Intercept)&quot;</span>
names(beta_truth) &lt;- nms

norm.beta.diff &lt;- rep(<span class="hljs-literal">NA</span>, <span class="hljs-number">20</span>)
<span class="hljs-keyword">for</span> (ii <span class="hljs-keyword">in</span> <span class="hljs-number">1</span>:<span class="hljs-number">20</span>) {
    coefi &lt;- coef(regfit.full, id = ii)
    norm.beta.diff[ii] &lt;- sqrt(sum((beta_truth[names(coefi)] - coefi)^<span class="hljs-number">2</span>))
}

plot(<span class="hljs-number">1</span>:<span class="hljs-number">20</span>, norm.beta.diff, xlab = <span class="hljs-string">&quot;number of predictors&quot;</span>, ylab = <span class="hljs-string">&quot;||beta_truth - beta^r||&quot;</span>, type = <span class="hljs-string">&quot;o&quot;</span>, col = <span class="hljs-string">&quot;green&quot;</span>)
grid()
</code></pre>
<p><img src="solutions_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-3-2.png" alt=""></p>
<h3 id="exercise-11">Exercise 11</h3>
<pre><code class="lang-r"><span class="hljs-keyword">library</span>(MASS)

set.seed(<span class="hljs-number">0</span>)

n &lt;- dim(Boston)[<span class="hljs-number">1</span>]
p &lt;- dim(Boston)[<span class="hljs-number">2</span>]

train &lt;- sample(c(<span class="hljs-literal">TRUE</span>, <span class="hljs-literal">FALSE</span>), n, rep = <span class="hljs-literal">TRUE</span>)  <span class="hljs-comment"># will roughly assign TRUE to one-half of the data (FALSE to the other half).</span>
test &lt;- (!train)

Boston_train &lt;- Boston[train, ]
Boston_test &lt;- Boston[test, ]

<span class="hljs-comment"># The full linear model:</span>
m &lt;- lm(crim ~ ., data = Boston_train)

Y_hat &lt;- predict(m, newdata = Boston_test)
MSE &lt;- mean((Boston_test$crim - Y_hat)^<span class="hljs-number">2</span>)
print(sprintf(<span class="hljs-string">&quot;Linear model test MSE= %10.3f&quot;</span>, MSE))
</code></pre>
<pre><code>## [1] &quot;Linear model test MSE=     34.996&quot;
</code></pre><pre><code class="lang-r"><span class="hljs-comment"># Ridge regression:</span>
Y &lt;- Boston_train$crim
MM &lt;- model.matrix(crim ~ ., data = Boston_train)
cv.out &lt;- cv.glmnet(MM, Y, alpha = <span class="hljs-number">0</span>)
plot(cv.out)
</code></pre>
<p><img src="solutions_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-4-1.png" alt=""></p>
<pre><code class="lang-r">bestlam &lt;- cv.out$lambda.1se
<span class="hljs-comment"># print( &apos;ridge regression CV best value of lambda (one standard error)&apos; ) print( bestlam )</span>

ridge.mod &lt;- glmnet(MM, Y, alpha = <span class="hljs-number">0</span>)

Y_hat &lt;- predict(ridge.mod, s = bestlam, newx = model.matrix(crim ~ ., data = Boston_test))
MSE &lt;- mean((Boston_test$crim - Y_hat)^<span class="hljs-number">2</span>)
print(sprintf(<span class="hljs-string">&quot;Ridge regression test MSE= %10.3f&quot;</span>, MSE))
</code></pre>
<pre><code>## [1] &quot;Ridge regression test MSE=     63.826&quot;
</code></pre><pre><code class="lang-r"><span class="hljs-comment"># The Lasso:</span>
cv.out &lt;- cv.glmnet(MM, Y, alpha = <span class="hljs-number">1</span>)
plot(cv.out)
</code></pre>
<p><img src="solutions_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-4-2.png" alt=""></p>
<pre><code class="lang-r">bestlam &lt;- cv.out$lambda.1se
<span class="hljs-comment"># print( &apos;lasso CV best value of lambda (one standard error)&apos; ) print( bestlam )</span>

lasso.mod &lt;- glmnet(MM, Y, alpha = <span class="hljs-number">1</span>)

Y_hat &lt;- predict(lasso.mod, s = bestlam, newx = model.matrix(crim ~ ., data = Boston_test))
MSE &lt;- mean((Boston_test$crim - Y_hat)^<span class="hljs-number">2</span>)
print(sprintf(<span class="hljs-string">&quot;Lasso regression test MSE= %10.3f&quot;</span>, MSE))
</code></pre>
<pre><code>## [1] &quot;Lasso regression test MSE=     63.572&quot;
</code></pre><pre><code class="lang-r">print(<span class="hljs-string">&quot;lasso coefficients&quot;</span>)
</code></pre>
<pre><code>## [1] &quot;lasso coefficients&quot;
</code></pre><pre><code class="lang-r">print(predict(lasso.mod, type = <span class="hljs-string">&quot;coefficients&quot;</span>, s = bestlam))
</code></pre>
<pre><code>## 15 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                      1
## (Intercept) 3.07011734
## (Intercept) .         
## zn          .         
## indus       .         
## chas        .         
## nox         .         
## rm          .         
## age         .         
## dis         .         
## rad         0.05507813
## tax         .         
## ptratio     .         
## black       .         
## lstat       .         
## medv        .
</code></pre><pre><code class="lang-r"><span class="hljs-comment"># Principle Component Regression:</span>
pcr.mod &lt;- pcr(crim ~ ., data = Boston_train, scale = <span class="hljs-literal">TRUE</span>, validation = <span class="hljs-string">&quot;CV&quot;</span>)

<span class="hljs-comment"># Use this to select the number of components to include ... looks like CV suggests we should use 3 predictors</span>
validationplot(pcr.mod, val.type = <span class="hljs-string">&quot;MSEP&quot;</span>)
</code></pre>
<p><img src="solutions_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-4-3.png" alt=""></p>
<pre><code class="lang-r">ncomp &lt;- <span class="hljs-number">3</span>
Y_hat &lt;- predict(pcr.mod, Boston_test, ncomp = ncomp)
MSE &lt;- mean((Boston_test$crim - Y_hat)^<span class="hljs-number">2</span>)
print(sprintf(<span class="hljs-string">&quot;PCR (with ncomp= %5d) test MSE= %10.3f&quot;</span>, ncomp, MSE))
</code></pre>
<pre><code>## [1] &quot;PCR (with ncomp=     3) test MSE=     40.049&quot;
</code></pre><pre><code class="lang-r"><span class="hljs-comment"># Paritial Least Squares:</span>
pls.mod &lt;- plsr(crim ~ ., data = Boston_train, scale = <span class="hljs-literal">TRUE</span>, validation = <span class="hljs-string">&quot;CV&quot;</span>)

<span class="hljs-comment"># Use this to select the number of components to include ... looks like CV suggests the best is to use 5 predictors</span>
validationplot(pls.mod, val.type = <span class="hljs-string">&quot;MSEP&quot;</span>)
</code></pre>
<p><img src="solutions_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-4-4.png" alt=""></p>
<pre><code class="lang-r">ncomp &lt;- <span class="hljs-number">5</span>
Y_hat &lt;- predict(pls.mod, Boston_test, ncomp = ncomp)
MSE &lt;- mean((Boston_test$crim - Y_hat)^<span class="hljs-number">2</span>)
print(sprintf(<span class="hljs-string">&quot;PLS (with ncomp= %5d) test MSE= %10.3f&quot;</span>, ncomp, MSE))
</code></pre>
<pre><code>## [1] &quot;PLS (with ncomp=     5) test MSE=     35.258&quot;
</code></pre>
                    
                    </section>
                
                
                </div>
            </div>
        </div>

        
        <a href="../chapter6/lab.html" class="navigation navigation-prev " aria-label="Previous page: Lab"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="../chapter7/index.html" class="navigation navigation-next " aria-label="Next page: Chapter 7. Moving Beyond Linearity"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="../gitbook/app.js"></script>

<script>
require(["gitbook"], function(gitbook) {
    var config = {"fontSettings":{"theme":null,"family":"sans","size":2}};
    gitbook.start(config);
});
</script>

        
    </body>
    
</html>
