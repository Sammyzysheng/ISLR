<!DOCTYPE HTML>
<html lang="en" >
    
    <head>
        
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <title>Lab | An Introduction to Statistical Learning:</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 2.2.0">
        
        
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
        <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">
        
    <link rel="stylesheet" href="../gitbook/style.css">
    
    
        <link rel="stylesheet" href="../styles/website.css">
    

        
    
    
    <link rel="next" href="../chapter6/solutions.html" />
    
    
    <link rel="prev" href="../chapter6/index.html" />
    

        
    </head>
    <body>
        
        
    <div class="book" data-level="5.1" data-basepath=".." data-revision="Wed Aug 19 2015 19:44:06 GMT+0100 (BST)">
    

<div class="book-summary">
    <div class="book-search">
        <input type="text" placeholder="Type to search" class="form-control" />
    </div>
    <ul class="summary">
        
        
        
        

        

        
    
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="../index.html">
                
                        <i class="fa fa-check"></i>
                        
                        Introduction
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1" data-path="chapter2/index.html">
            
                
                    <a href="../chapter2/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                        Chapter 2. Statistical Learning
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1" data-path="chapter2/lab.html">
            
                
                    <a href="../chapter2/lab.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.</b>
                        
                        Lab
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="chapter2/solutions.html">
            
                
                    <a href="../chapter2/solutions.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.</b>
                        
                        Solutions
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2" data-path="chapter3/index.html">
            
                
                    <a href="../chapter3/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.</b>
                        
                        Chapter 3. Linear Regression
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1" data-path="chapter3/lab.html">
            
                
                    <a href="../chapter3/lab.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.</b>
                        
                        Lab
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="chapter3/solutions.html">
            
                
                    <a href="../chapter3/solutions.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.</b>
                        
                        Solutions
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3" data-path="chapter4/index.html">
            
                
                    <a href="../chapter4/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.</b>
                        
                        Chapter 4. Classification
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1" data-path="chapter4/lab.html">
            
                
                    <a href="../chapter4/lab.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.</b>
                        
                        Lab
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="chapter4/solutions.html">
            
                
                    <a href="../chapter4/solutions.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.</b>
                        
                        Solutions
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4" data-path="chapter5/index.html">
            
                
                    <a href="../chapter5/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.</b>
                        
                        Chapter 5. Resampling Methods
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.1" data-path="chapter5/lab.html">
            
                
                    <a href="../chapter5/lab.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.1.</b>
                        
                        Lab
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="chapter5/solutions.html">
            
                
                    <a href="../chapter5/solutions.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.2.</b>
                        
                        Solutions
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="5" data-path="chapter6/index.html">
            
                
                    <a href="../chapter6/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.</b>
                        
                        Chapter 6. Linear Model Selection and Regularization
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter active" data-level="5.1" data-path="chapter6/lab.html">
            
                
                    <a href="../chapter6/lab.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.1.</b>
                        
                        Lab
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.2" data-path="chapter6/solutions.html">
            
                
                    <a href="../chapter6/solutions.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.2.</b>
                        
                        Solutions
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="6" data-path="chapter7/index.html">
            
                
                    <a href="../chapter7/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.</b>
                        
                        Chapter 7. Moving Beyond Linearity
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="6.1" data-path="chapter7/lab.html">
            
                
                    <a href="../chapter7/lab.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.1.</b>
                        
                        Lab
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.2" data-path="chapter7/solutions.html">
            
                
                    <a href="../chapter7/solutions.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.2.</b>
                        
                        Solutions
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="7" data-path="chapter8/index.html">
            
                
                    <a href="../chapter8/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.</b>
                        
                        Chapter 8. Tree-Based Methods
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="7.1" data-path="chapter8/lab.html">
            
                
                    <a href="../chapter8/lab.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.1.</b>
                        
                        Lab
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.2" data-path="chapter8/solutions.html">
            
                
                    <a href="../chapter8/solutions.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.2.</b>
                        
                        Solutions
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="8" data-path="chapter9/index.html">
            
                
                    <a href="../chapter9/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.</b>
                        
                        Chapter 9. Support Vector Machines
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="8.1" data-path="chapter9/lab.html">
            
                
                    <a href="../chapter9/lab.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.1.</b>
                        
                        Lab
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="8.2" data-path="chapter9/solutions.html">
            
                
                    <a href="../chapter9/solutions.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.2.</b>
                        
                        Solutions
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="9" data-path="chapter10/index.html">
            
                
                    <a href="../chapter10/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.</b>
                        
                        Chapter 10. Unsupervised Learning
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="9.1" data-path="chapter10/lab.html">
            
                
                    <a href="../chapter10/lab.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.1.</b>
                        
                        Lab
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9.2" data-path="chapter10/solutions.html">
            
                
                    <a href="../chapter10/solutions.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.2.</b>
                        
                        Solutions
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="10" data-path="references.html">
            
                
                    <a href="../references.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.</b>
                        
                        References
                    </a>
            
            
        </li>
    


        
        <li class="divider"></li>
        <li>
            <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
                Published with GitBook
            </a>
        </li>
        
    </ul>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="book-header">
    <!-- Actions Left -->
    <a href="#" class="btn pull-left toggle-summary" aria-label="Table of Contents"><i class="fa fa-align-justify"></i></a>
    <a href="#" class="btn pull-left toggle-search" aria-label="Search"><i class="fa fa-search"></i></a>
    
    <div id="font-settings-wrapper" class="dropdown pull-left">
        <a href="#" class="btn toggle-dropdown" aria-label="Font Settings"><i class="fa fa-font"></i>
        </a>
        <div class="dropdown-menu font-settings">
    <div class="dropdown-caret">
        <span class="caret-outer"></span>
        <span class="caret-inner"></span>
    </div>

    <div class="buttons">
        <button type="button" id="reduce-font-size" class="button size-2">A</button>
        <button type="button" id="enlarge-font-size" class="button size-2">A</button>
    </div>

    <div class="buttons font-family-list">
        <button type="button" data-font="0" class="button">Serif</button>
        <button type="button" data-font="1" class="button">Sans</button>
    </div>

    <div class="buttons color-theme-list">
        <button type="button" id="color-theme-preview-0" class="button size-3" data-theme="0">White</button>
        <button type="button" id="color-theme-preview-1" class="button size-3" data-theme="1">Sepia</button>
        <button type="button" id="color-theme-preview-2" class="button size-3" data-theme="2">Night</button>
    </div>
</div>

    </div>

    <!-- Actions Right -->
    
    <div class="dropdown pull-right">
        <a href="#" class="btn toggle-dropdown" aria-label="Share"><i class="fa fa-share-alt"></i>
        </a>
        <div class="dropdown-menu font-settings dropdown-left">
            <div class="dropdown-caret">
                <span class="caret-outer"></span>
                <span class="caret-inner"></span>
            </div>
            <div class="buttons">
                <button type="button" data-sharing="twitter" class="button">
                    Share on Twitter
                </button>
                <button type="button" data-sharing="google-plus" class="button">
                    Share on Google
                </button>
                <button type="button" data-sharing="facebook" class="button">
                    Share on Facebook
                </button>
                <button type="button" data-sharing="weibo" class="button">
                    Share on Weibo
                </button>
                <button type="button" data-sharing="instapaper" class="button">
                    Share on Instapaper
                </button>
            </div>
        </div>
    </div>
    

    
    <a href="#" target="_blank" class="btn pull-right google-plus-sharing-link sharing-link" data-sharing="google-plus" aria-label="Google"><i class="fa fa-google-plus"></i></a>
    
    
    <a href="#" target="_blank" class="btn pull-right facebook-sharing-link sharing-link" data-sharing="facebook" aria-label="Facebook"><i class="fa fa-facebook"></i></a>
    
    
    <a href="#" target="_blank" class="btn pull-right twitter-sharing-link sharing-link" data-sharing="twitter" aria-label="Twitter"><i class="fa fa-twitter"></i></a>
    
    
    


    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../" >An Introduction to Statistical Learning:</a>
    </h1>
</div>

            <div class="page-wrapper" tabindex="-1">
                <div class="page-inner">
                
                
                    <section class="normal" id="section-">
                    
                        <h2 id="6-5-lab-1-subset-selection-methods">6.5 Lab 1: Subset Selection Methods</h2>
<h3 id="6-5-1-best-subset-selection">6.5.1 Best Subset Selection</h3>
<p>We start by loading the <code>ISLR</code> package and examining the <code>Hitters</code> dataset. We use the <a href="http://bit.ly/R_NA" target="_blank"><code>is.na()</code></a> function and count the number of observations where the <code>Salary</code> variable is missing.</p>
<pre><code class="lang-r"><span class="hljs-keyword">library</span>(ISLR)
head(Hitters)
</code></pre>
<pre><code>##                   AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits
## -Andy Allanson      293   66     1   30  29    14     1    293    66
## -Alan Ashby         315   81     7   24  38    39    14   3449   835
## -Alvin Davis        479  130    18   66  72    76     3   1624   457
## -Andre Dawson       496  141    20   65  78    37    11   5628  1575
## -Andres Galarraga   321   87    10   39  42    30     2    396   101
## -Alfredo Griffin    594  169     4   74  51    35    11   4408  1133
##                   CHmRun CRuns CRBI CWalks League Division PutOuts Assists
## -Andy Allanson         1    30   29     14      A        E     446      33
## -Alan Ashby           69   321  414    375      N        W     632      43
## -Alvin Davis          63   224  266    263      A        W     880      82
## -Andre Dawson        225   828  838    354      N        E     200      11
## -Andres Galarraga     12    48   46     33      N        E     805      40
## -Alfredo Griffin      19   501  336    194      A        W     282     421
##                   Errors Salary NewLeague
## -Andy Allanson        20     NA         A
## -Alan Ashby           10  475.0         N
## -Alvin Davis          14  480.0         A
## -Andre Dawson          3  500.0         N
## -Andres Galarraga      4   91.5         N
## -Alfredo Griffin      25  750.0         A
</code></pre><pre><code class="lang-r">names(Hitters)
</code></pre>
<pre><code>##  [1] &quot;AtBat&quot;     &quot;Hits&quot;      &quot;HmRun&quot;     &quot;Runs&quot;      &quot;RBI&quot;      
##  [6] &quot;Walks&quot;     &quot;Years&quot;     &quot;CAtBat&quot;    &quot;CHits&quot;     &quot;CHmRun&quot;   
## [11] &quot;CRuns&quot;     &quot;CRBI&quot;      &quot;CWalks&quot;    &quot;League&quot;    &quot;Division&quot; 
## [16] &quot;PutOuts&quot;   &quot;Assists&quot;   &quot;Errors&quot;    &quot;Salary&quot;    &quot;NewLeague&quot;
</code></pre><pre><code class="lang-r">dim(Hitters)
</code></pre>
<pre><code>## [1] 322  20
</code></pre><pre><code class="lang-r">sum(is.na(Hitters$Salary))
</code></pre>
<pre><code>## [1] 59
</code></pre><p>We can remove all observations with missing values with <a href="http://bit.ly/R_na_fail" target="_blank"><code>na.omit()</code></a>.</p>
<pre><code class="lang-r">Hitters &lt;- na.omit(Hitters)
dim(Hitters)
</code></pre>
<pre><code>## [1] 263  20
</code></pre><pre><code class="lang-r">sum(is.na(Hitters))
</code></pre>
<pre><code>## [1] 0
</code></pre><p>We use the <a href="http://bit.ly/R_regsubsets" target="_blank"><code>regsubsets()</code></a> function to identify the best model based on subset selection quantified by the residual sum of squares (RSS) for each model.</p>
<pre><code class="lang-r"><span class="hljs-keyword">library</span>(leaps)
regfit.full &lt;- regsubsets(Salary ~ ., Hitters)
summary(regfit.full)
</code></pre>
<pre><code>## Subset selection object
## Call: regsubsets.formula(Salary ~ ., Hitters)
## 19 Variables  (and intercept)
##            Forced in Forced out
## AtBat          FALSE      FALSE
## Hits           FALSE      FALSE
## HmRun          FALSE      FALSE
## Runs           FALSE      FALSE
## RBI            FALSE      FALSE
## Walks          FALSE      FALSE
## Years          FALSE      FALSE
## CAtBat         FALSE      FALSE
## CHits          FALSE      FALSE
## CHmRun         FALSE      FALSE
## CRuns          FALSE      FALSE
## CRBI           FALSE      FALSE
## CWalks         FALSE      FALSE
## LeagueN        FALSE      FALSE
## DivisionW      FALSE      FALSE
## PutOuts        FALSE      FALSE
## Assists        FALSE      FALSE
## Errors         FALSE      FALSE
## NewLeagueN     FALSE      FALSE
## 1 subsets of each size up to 8
## Selection Algorithm: exhaustive
##          AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns
## 1  ( 1 ) &quot; &quot;   &quot; &quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot; &quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot; &quot;    &quot; &quot;  
## 2  ( 1 ) &quot; &quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot; &quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot; &quot;    &quot; &quot;  
## 3  ( 1 ) &quot; &quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot; &quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot; &quot;    &quot; &quot;  
## 4  ( 1 ) &quot; &quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot; &quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot; &quot;    &quot; &quot;  
## 5  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot; &quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot; &quot;    &quot; &quot;  
## 6  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot; &quot;    &quot; &quot;  
## 7  ( 1 ) &quot; &quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot;*&quot;    &quot;*&quot;   &quot;*&quot;    &quot; &quot;  
## 8  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot;*&quot;    &quot;*&quot;  
##          CRBI CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN
## 1  ( 1 ) &quot;*&quot;  &quot; &quot;    &quot; &quot;     &quot; &quot;       &quot; &quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 2  ( 1 ) &quot;*&quot;  &quot; &quot;    &quot; &quot;     &quot; &quot;       &quot; &quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 3  ( 1 ) &quot;*&quot;  &quot; &quot;    &quot; &quot;     &quot; &quot;       &quot;*&quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 4  ( 1 ) &quot;*&quot;  &quot; &quot;    &quot; &quot;     &quot;*&quot;       &quot;*&quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 5  ( 1 ) &quot;*&quot;  &quot; &quot;    &quot; &quot;     &quot;*&quot;       &quot;*&quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 6  ( 1 ) &quot;*&quot;  &quot; &quot;    &quot; &quot;     &quot;*&quot;       &quot;*&quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 7  ( 1 ) &quot; &quot;  &quot; &quot;    &quot; &quot;     &quot;*&quot;       &quot;*&quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 8  ( 1 ) &quot; &quot;  &quot;*&quot;    &quot; &quot;     &quot;*&quot;       &quot;*&quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;
</code></pre><p>The <code>nvmax</code> parameter can be use to control the number of variables in the model. The default used by <a href="http://bit.ly/R_regsubsets" target="_blank"><code>regsubsets()</code></a> is 8.</p>
<pre><code class="lang-r">regfit.full &lt;- regsubsets(Salary ~ ., data = Hitters, nvmax = <span class="hljs-number">19</span>)
reg.summary &lt;- summary(regfit.full)
</code></pre>
<p>We can look at the components of the <code>reg.summary</code> variable using the <a href="http://bit.ly/R_names" target="_blank"><code>names()</code></a> function and examine the (R^2) statistic stored in <code>rsq</code>.</p>
<pre><code class="lang-r">names(reg.summary)
</code></pre>
<pre><code>## [1] &quot;which&quot;  &quot;rsq&quot;    &quot;rss&quot;    &quot;adjr2&quot;  &quot;cp&quot;     &quot;bic&quot;    &quot;outmat&quot; &quot;obj&quot;
</code></pre><pre><code class="lang-r">reg.summary$rsq
</code></pre>
<pre><code>##  [1] 0.3214501 0.4252237 0.4514294 0.4754067 0.4908036 0.5087146 0.5141227
##  [8] 0.5285569 0.5346124 0.5404950 0.5426153 0.5436302 0.5444570 0.5452164
## [15] 0.5454692 0.5457656 0.5459518 0.5460945 0.5461159
</code></pre><p>Next, we plot the RSS and adjusted (R^2) and add a point where (R^2) is at its maximum using the <a href="http://bit.ly/R_extremes" target="_blank"><code>which.max()</code></a> function.</p>
<pre><code class="lang-r">par(mfrow = c(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>))
plot(reg.summary$rss, xlab = <span class="hljs-string">&quot;Number of Variables&quot;</span>, ylab = <span class="hljs-string">&quot;RSS&quot;</span>, type = <span class="hljs-string">&quot;l&quot;</span>)
plot(reg.summary$adjr2, xlab = <span class="hljs-string">&quot;Number of Variables&quot;</span>, ylab = <span class="hljs-string">&quot;Adjusted RSq&quot;</span>, type = <span class="hljs-string">&quot;l&quot;</span>)

adjr2.max &lt;- which.max(reg.summary$adjr2)
points(adjr2.max, reg.summary$adjr2[adjr2.max], col = <span class="hljs-string">&quot;red&quot;</span>, cex = <span class="hljs-number">2</span>, pch = <span class="hljs-number">20</span>)
</code></pre>
<p><img src="lab_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-7-1.png" alt=""></p>
<p>We can also plot the the (C_p) statistic and <em>BIC</em> and identify the minimum points for each statistic using the <a href="http://bit.ly/R_extremes" target="_blank"><code>which.min()</code></a> function.</p>
<pre><code class="lang-r">plot(reg.summary$cp, xlab = <span class="hljs-string">&quot;Number of Variables&quot;</span>, ylab = <span class="hljs-string">&quot;Cp&quot;</span>, type = <span class="hljs-string">&quot;l&quot;</span>)
cp.min &lt;- which.min(reg.summary$cp)
points(cp.min, reg.summary$cp[cp.min], col = <span class="hljs-string">&quot;red&quot;</span>, cex = <span class="hljs-number">2</span>, pch = <span class="hljs-number">20</span>)
</code></pre>
<p><img src="lab_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-8-1.png" alt=""></p>
<pre><code class="lang-r">bic.min &lt;- which.min(reg.summary$bic)
plot(reg.summary$bic, xlab = <span class="hljs-string">&quot;Number of Variables&quot;</span>, ylab = <span class="hljs-string">&quot;BIC&quot;</span>, type = <span class="hljs-string">&quot;l&quot;</span>)
points(bic.min, reg.summary$bic[bic.min], col = <span class="hljs-string">&quot;red&quot;</span>, cex = <span class="hljs-number">2</span>, pch = <span class="hljs-number">20</span>)
</code></pre>
<p><img src="lab_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-8-2.png" alt=""></p>
<p>The estimated models from <a href="http://bit.ly/R_regsubsets" target="_blank"><code>regsubsets()</code></a> can be directly plotted to compare the differences based on the values of (R^2), adjusted (R^2), (C_p) and <em>BIC</em> statistics.</p>
<pre><code class="lang-r">plot(regfit.full, scale = <span class="hljs-string">&quot;r2&quot;</span>)
</code></pre>
<p><img src="lab_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-9-1.png" alt=""></p>
<pre><code class="lang-r">plot(regfit.full, scale = <span class="hljs-string">&quot;adjr2&quot;</span>)
</code></pre>
<p><img src="lab_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-9-2.png" alt=""></p>
<pre><code class="lang-r">plot(regfit.full, scale = <span class="hljs-string">&quot;Cp&quot;</span>)
</code></pre>
<p><img src="lab_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-9-3.png" alt=""></p>
<pre><code class="lang-r">plot(regfit.full, scale = <span class="hljs-string">&quot;bic&quot;</span>)
</code></pre>
<p><img src="lab_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-9-4.png" alt=""></p>
<p>To show the coefficients associated with the model with the lowest <em>BIC</em>, we use the <a href="http://bit.ly/R_coef" target="_blank"><code>coef()</code></a> function.</p>
<pre><code class="lang-r">coef(regfit.full, bic.min)
</code></pre>
<pre><code>##  (Intercept)        AtBat         Hits        Walks         CRBI 
##   91.5117981   -1.8685892    7.6043976    3.6976468    0.6430169 
##    DivisionW      PutOuts 
## -122.9515338    0.2643076
</code></pre><h3 id="6-5-2-forward-and-backward-stepwise-selection">6.5.2 Forward and Backward Stepwise Selection</h3>
<p>The default method used by <a href="http://bit.ly/R_regsubsets" target="_blank"><code>regsubsets()</code></a> is <code>exhaustive</code> but we can change it to <code>forward</code> or <code>backward</code> and compare the results.</p>
<pre><code class="lang-r">regfit.fwd &lt;- regsubsets(Salary ~ ., data = Hitters, nvmax = <span class="hljs-number">19</span>, method = <span class="hljs-string">&quot;forward&quot;</span>)
summary(regfit.fwd)
</code></pre>
<pre><code>## Subset selection object
## Call: regsubsets.formula(Salary ~ ., data = Hitters, nvmax = 19, method = &quot;forward&quot;)
## 19 Variables  (and intercept)
##            Forced in Forced out
## AtBat          FALSE      FALSE
## Hits           FALSE      FALSE
## HmRun          FALSE      FALSE
## Runs           FALSE      FALSE
## RBI            FALSE      FALSE
## Walks          FALSE      FALSE
## Years          FALSE      FALSE
## CAtBat         FALSE      FALSE
## CHits          FALSE      FALSE
## CHmRun         FALSE      FALSE
## CRuns          FALSE      FALSE
## CRBI           FALSE      FALSE
## CWalks         FALSE      FALSE
## LeagueN        FALSE      FALSE
## DivisionW      FALSE      FALSE
## PutOuts        FALSE      FALSE
## Assists        FALSE      FALSE
## Errors         FALSE      FALSE
## NewLeagueN     FALSE      FALSE
## 1 subsets of each size up to 19
## Selection Algorithm: forward
##           AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns
## 1  ( 1 )  &quot; &quot;   &quot; &quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot; &quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot; &quot;    &quot; &quot;  
## 2  ( 1 )  &quot; &quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot; &quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot; &quot;    &quot; &quot;  
## 3  ( 1 )  &quot; &quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot; &quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot; &quot;    &quot; &quot;  
## 4  ( 1 )  &quot; &quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot; &quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot; &quot;    &quot; &quot;  
## 5  ( 1 )  &quot;*&quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot; &quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot; &quot;    &quot; &quot;  
## 6  ( 1 )  &quot;*&quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot; &quot;    &quot; &quot;  
## 7  ( 1 )  &quot;*&quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot; &quot;    &quot; &quot;  
## 8  ( 1 )  &quot;*&quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot; &quot;    &quot;*&quot;  
## 9  ( 1 )  &quot;*&quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot;*&quot;    &quot; &quot;   &quot; &quot;    &quot;*&quot;  
## 10  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot;*&quot;    &quot; &quot;   &quot; &quot;    &quot;*&quot;  
## 11  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot;*&quot;    &quot; &quot;   &quot; &quot;    &quot;*&quot;  
## 12  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot; &quot;   &quot;*&quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot;*&quot;    &quot; &quot;   &quot; &quot;    &quot;*&quot;  
## 13  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot; &quot;   &quot;*&quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot;*&quot;    &quot; &quot;   &quot; &quot;    &quot;*&quot;  
## 14  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot;*&quot;   &quot;*&quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot;*&quot;    &quot; &quot;   &quot; &quot;    &quot;*&quot;  
## 15  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot;*&quot;   &quot;*&quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot;*&quot;    &quot;*&quot;   &quot; &quot;    &quot;*&quot;  
## 16  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot;*&quot;   &quot;*&quot;  &quot;*&quot; &quot;*&quot;   &quot; &quot;   &quot;*&quot;    &quot;*&quot;   &quot; &quot;    &quot;*&quot;  
## 17  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot;*&quot;   &quot;*&quot;  &quot;*&quot; &quot;*&quot;   &quot; &quot;   &quot;*&quot;    &quot;*&quot;   &quot; &quot;    &quot;*&quot;  
## 18  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot;*&quot;   &quot;*&quot;  &quot;*&quot; &quot;*&quot;   &quot;*&quot;   &quot;*&quot;    &quot;*&quot;   &quot; &quot;    &quot;*&quot;  
## 19  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot;*&quot;   &quot;*&quot;  &quot;*&quot; &quot;*&quot;   &quot;*&quot;   &quot;*&quot;    &quot;*&quot;   &quot;*&quot;    &quot;*&quot;  
##           CRBI CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN
## 1  ( 1 )  &quot;*&quot;  &quot; &quot;    &quot; &quot;     &quot; &quot;       &quot; &quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 2  ( 1 )  &quot;*&quot;  &quot; &quot;    &quot; &quot;     &quot; &quot;       &quot; &quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 3  ( 1 )  &quot;*&quot;  &quot; &quot;    &quot; &quot;     &quot; &quot;       &quot;*&quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 4  ( 1 )  &quot;*&quot;  &quot; &quot;    &quot; &quot;     &quot;*&quot;       &quot;*&quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 5  ( 1 )  &quot;*&quot;  &quot; &quot;    &quot; &quot;     &quot;*&quot;       &quot;*&quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 6  ( 1 )  &quot;*&quot;  &quot; &quot;    &quot; &quot;     &quot;*&quot;       &quot;*&quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 7  ( 1 )  &quot;*&quot;  &quot;*&quot;    &quot; &quot;     &quot;*&quot;       &quot;*&quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 8  ( 1 )  &quot;*&quot;  &quot;*&quot;    &quot; &quot;     &quot;*&quot;       &quot;*&quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 9  ( 1 )  &quot;*&quot;  &quot;*&quot;    &quot; &quot;     &quot;*&quot;       &quot;*&quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 10  ( 1 ) &quot;*&quot;  &quot;*&quot;    &quot; &quot;     &quot;*&quot;       &quot;*&quot;     &quot;*&quot;     &quot; &quot;    &quot; &quot;       
## 11  ( 1 ) &quot;*&quot;  &quot;*&quot;    &quot;*&quot;     &quot;*&quot;       &quot;*&quot;     &quot;*&quot;     &quot; &quot;    &quot; &quot;       
## 12  ( 1 ) &quot;*&quot;  &quot;*&quot;    &quot;*&quot;     &quot;*&quot;       &quot;*&quot;     &quot;*&quot;     &quot; &quot;    &quot; &quot;       
## 13  ( 1 ) &quot;*&quot;  &quot;*&quot;    &quot;*&quot;     &quot;*&quot;       &quot;*&quot;     &quot;*&quot;     &quot;*&quot;    &quot; &quot;       
## 14  ( 1 ) &quot;*&quot;  &quot;*&quot;    &quot;*&quot;     &quot;*&quot;       &quot;*&quot;     &quot;*&quot;     &quot;*&quot;    &quot; &quot;       
## 15  ( 1 ) &quot;*&quot;  &quot;*&quot;    &quot;*&quot;     &quot;*&quot;       &quot;*&quot;     &quot;*&quot;     &quot;*&quot;    &quot; &quot;       
## 16  ( 1 ) &quot;*&quot;  &quot;*&quot;    &quot;*&quot;     &quot;*&quot;       &quot;*&quot;     &quot;*&quot;     &quot;*&quot;    &quot; &quot;       
## 17  ( 1 ) &quot;*&quot;  &quot;*&quot;    &quot;*&quot;     &quot;*&quot;       &quot;*&quot;     &quot;*&quot;     &quot;*&quot;    &quot;*&quot;       
## 18  ( 1 ) &quot;*&quot;  &quot;*&quot;    &quot;*&quot;     &quot;*&quot;       &quot;*&quot;     &quot;*&quot;     &quot;*&quot;    &quot;*&quot;       
## 19  ( 1 ) &quot;*&quot;  &quot;*&quot;    &quot;*&quot;     &quot;*&quot;       &quot;*&quot;     &quot;*&quot;     &quot;*&quot;    &quot;*&quot;
</code></pre><pre><code class="lang-r">regfit.bwd &lt;- regsubsets(Salary ~ ., data = Hitters, nvmax = <span class="hljs-number">19</span>, method = <span class="hljs-string">&quot;backward&quot;</span>)
summary(regfit.bwd)
</code></pre>
<pre><code>## Subset selection object
## Call: regsubsets.formula(Salary ~ ., data = Hitters, nvmax = 19, method = &quot;backward&quot;)
## 19 Variables  (and intercept)
##            Forced in Forced out
## AtBat          FALSE      FALSE
## Hits           FALSE      FALSE
## HmRun          FALSE      FALSE
## Runs           FALSE      FALSE
## RBI            FALSE      FALSE
## Walks          FALSE      FALSE
## Years          FALSE      FALSE
## CAtBat         FALSE      FALSE
## CHits          FALSE      FALSE
## CHmRun         FALSE      FALSE
## CRuns          FALSE      FALSE
## CRBI           FALSE      FALSE
## CWalks         FALSE      FALSE
## LeagueN        FALSE      FALSE
## DivisionW      FALSE      FALSE
## PutOuts        FALSE      FALSE
## Assists        FALSE      FALSE
## Errors         FALSE      FALSE
## NewLeagueN     FALSE      FALSE
## 1 subsets of each size up to 19
## Selection Algorithm: backward
##           AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns
## 1  ( 1 )  &quot; &quot;   &quot; &quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot; &quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot; &quot;    &quot;*&quot;  
## 2  ( 1 )  &quot; &quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot; &quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot; &quot;    &quot;*&quot;  
## 3  ( 1 )  &quot; &quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot; &quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot; &quot;    &quot;*&quot;  
## 4  ( 1 )  &quot;*&quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot; &quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot; &quot;    &quot;*&quot;  
## 5  ( 1 )  &quot;*&quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot; &quot;    &quot;*&quot;  
## 6  ( 1 )  &quot;*&quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot; &quot;    &quot;*&quot;  
## 7  ( 1 )  &quot;*&quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot; &quot;    &quot;*&quot;  
## 8  ( 1 )  &quot;*&quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot; &quot;    &quot; &quot;   &quot; &quot;    &quot;*&quot;  
## 9  ( 1 )  &quot;*&quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot;*&quot;    &quot; &quot;   &quot; &quot;    &quot;*&quot;  
## 10  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot;*&quot;    &quot; &quot;   &quot; &quot;    &quot;*&quot;  
## 11  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot; &quot;   &quot; &quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot;*&quot;    &quot; &quot;   &quot; &quot;    &quot;*&quot;  
## 12  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot; &quot;   &quot;*&quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot;*&quot;    &quot; &quot;   &quot; &quot;    &quot;*&quot;  
## 13  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot; &quot;   &quot;*&quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot;*&quot;    &quot; &quot;   &quot; &quot;    &quot;*&quot;  
## 14  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot;*&quot;   &quot;*&quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot;*&quot;    &quot; &quot;   &quot; &quot;    &quot;*&quot;  
## 15  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot;*&quot;   &quot;*&quot;  &quot; &quot; &quot;*&quot;   &quot; &quot;   &quot;*&quot;    &quot;*&quot;   &quot; &quot;    &quot;*&quot;  
## 16  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot;*&quot;   &quot;*&quot;  &quot;*&quot; &quot;*&quot;   &quot; &quot;   &quot;*&quot;    &quot;*&quot;   &quot; &quot;    &quot;*&quot;  
## 17  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot;*&quot;   &quot;*&quot;  &quot;*&quot; &quot;*&quot;   &quot; &quot;   &quot;*&quot;    &quot;*&quot;   &quot; &quot;    &quot;*&quot;  
## 18  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot;*&quot;   &quot;*&quot;  &quot;*&quot; &quot;*&quot;   &quot;*&quot;   &quot;*&quot;    &quot;*&quot;   &quot; &quot;    &quot;*&quot;  
## 19  ( 1 ) &quot;*&quot;   &quot;*&quot;  &quot;*&quot;   &quot;*&quot;  &quot;*&quot; &quot;*&quot;   &quot;*&quot;   &quot;*&quot;    &quot;*&quot;   &quot;*&quot;    &quot;*&quot;  
##           CRBI CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN
## 1  ( 1 )  &quot; &quot;  &quot; &quot;    &quot; &quot;     &quot; &quot;       &quot; &quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 2  ( 1 )  &quot; &quot;  &quot; &quot;    &quot; &quot;     &quot; &quot;       &quot; &quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 3  ( 1 )  &quot; &quot;  &quot; &quot;    &quot; &quot;     &quot; &quot;       &quot;*&quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 4  ( 1 )  &quot; &quot;  &quot; &quot;    &quot; &quot;     &quot; &quot;       &quot;*&quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 5  ( 1 )  &quot; &quot;  &quot; &quot;    &quot; &quot;     &quot; &quot;       &quot;*&quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 6  ( 1 )  &quot; &quot;  &quot; &quot;    &quot; &quot;     &quot;*&quot;       &quot;*&quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 7  ( 1 )  &quot; &quot;  &quot;*&quot;    &quot; &quot;     &quot;*&quot;       &quot;*&quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 8  ( 1 )  &quot;*&quot;  &quot;*&quot;    &quot; &quot;     &quot;*&quot;       &quot;*&quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 9  ( 1 )  &quot;*&quot;  &quot;*&quot;    &quot; &quot;     &quot;*&quot;       &quot;*&quot;     &quot; &quot;     &quot; &quot;    &quot; &quot;       
## 10  ( 1 ) &quot;*&quot;  &quot;*&quot;    &quot; &quot;     &quot;*&quot;       &quot;*&quot;     &quot;*&quot;     &quot; &quot;    &quot; &quot;       
## 11  ( 1 ) &quot;*&quot;  &quot;*&quot;    &quot;*&quot;     &quot;*&quot;       &quot;*&quot;     &quot;*&quot;     &quot; &quot;    &quot; &quot;       
## 12  ( 1 ) &quot;*&quot;  &quot;*&quot;    &quot;*&quot;     &quot;*&quot;       &quot;*&quot;     &quot;*&quot;     &quot; &quot;    &quot; &quot;       
## 13  ( 1 ) &quot;*&quot;  &quot;*&quot;    &quot;*&quot;     &quot;*&quot;       &quot;*&quot;     &quot;*&quot;     &quot;*&quot;    &quot; &quot;       
## 14  ( 1 ) &quot;*&quot;  &quot;*&quot;    &quot;*&quot;     &quot;*&quot;       &quot;*&quot;     &quot;*&quot;     &quot;*&quot;    &quot; &quot;       
## 15  ( 1 ) &quot;*&quot;  &quot;*&quot;    &quot;*&quot;     &quot;*&quot;       &quot;*&quot;     &quot;*&quot;     &quot;*&quot;    &quot; &quot;       
## 16  ( 1 ) &quot;*&quot;  &quot;*&quot;    &quot;*&quot;     &quot;*&quot;       &quot;*&quot;     &quot;*&quot;     &quot;*&quot;    &quot; &quot;       
## 17  ( 1 ) &quot;*&quot;  &quot;*&quot;    &quot;*&quot;     &quot;*&quot;       &quot;*&quot;     &quot;*&quot;     &quot;*&quot;    &quot;*&quot;       
## 18  ( 1 ) &quot;*&quot;  &quot;*&quot;    &quot;*&quot;     &quot;*&quot;       &quot;*&quot;     &quot;*&quot;     &quot;*&quot;    &quot;*&quot;       
## 19  ( 1 ) &quot;*&quot;  &quot;*&quot;    &quot;*&quot;     &quot;*&quot;       &quot;*&quot;     &quot;*&quot;     &quot;*&quot;    &quot;*&quot;
</code></pre><pre><code class="lang-r">coef(regfit.full, <span class="hljs-number">7</span>)
</code></pre>
<pre><code>##  (Intercept)         Hits        Walks       CAtBat        CHits 
##   79.4509472    1.2833513    3.2274264   -0.3752350    1.4957073 
##       CHmRun    DivisionW      PutOuts 
##    1.4420538 -129.9866432    0.2366813
</code></pre><pre><code class="lang-r">coef(regfit.fwd, <span class="hljs-number">7</span>)
</code></pre>
<pre><code>##  (Intercept)        AtBat         Hits        Walks         CRBI 
##  109.7873062   -1.9588851    7.4498772    4.9131401    0.8537622 
##       CWalks    DivisionW      PutOuts 
##   -0.3053070 -127.1223928    0.2533404
</code></pre><pre><code class="lang-r">coef(regfit.bwd, <span class="hljs-number">7</span>)
</code></pre>
<pre><code>##  (Intercept)        AtBat         Hits        Walks        CRuns 
##  105.6487488   -1.9762838    6.7574914    6.0558691    1.1293095 
##       CWalks    DivisionW      PutOuts 
##   -0.7163346 -116.1692169    0.3028847
</code></pre><h3 id="6-5-3-choosing-among-models-using-the-validation-set-approach-and-cross-validation">6.5.3 Choosing Among Models Using the Validation Set Approach and Cross-Validation</h3>
<p>For validation set approach, we split the dataset into a training subset and a test subset. In order to ensure that the results are consistent over multiple iterations, we set the random seed with <a href="http://bit.ly/R_set_seed" target="_blank"><code>set.seed()</code></a> before calling <a href="http://bit.ly/R_sample" target="_blank"><code>sample()</code></a>.</p>
<pre><code class="lang-r">set.seed(<span class="hljs-number">1</span>)
train &lt;- sample(c(<span class="hljs-literal">TRUE</span>, <span class="hljs-literal">FALSE</span>), nrow(Hitters), rep = <span class="hljs-literal">TRUE</span>)
test &lt;- (!train)
</code></pre>
<p>We use <a href="http://bit.ly/R_regsubsets" target="_blank"><code>regsubsets()</code></a> as we did in the last section, but limit the estimation to the training subset.</p>
<pre><code class="lang-r">regfit.best &lt;- regsubsets(Salary ~ ., data = Hitters[train, ], nvmax = <span class="hljs-number">19</span>)
</code></pre>
<p>We create a matrix from the test subset using <a href="http://bit.ly/R_model_matrix" target="_blank"><code>model.matrix()</code></a>.</p>
<pre><code class="lang-r">test.mat &lt;- model.matrix(Salary ~ ., data = Hitters[test, ])
</code></pre>
<p>Next, we compute the validation error for each model.</p>
<pre><code class="lang-r">val.errors &lt;- rep(<span class="hljs-literal">NA</span>, <span class="hljs-number">19</span>)
<span class="hljs-keyword">for</span> (i <span class="hljs-keyword">in</span> <span class="hljs-number">1</span>:<span class="hljs-number">19</span>) {
    coefi &lt;- coef(regfit.best, id = i)
    pred &lt;- test.mat[, names(coefi)] %*% coefi
    val.errors[i] &lt;- mean((Hitters$Salary[test] - pred)^<span class="hljs-number">2</span>)
}
</code></pre>
<p>We examine the validation error for each model and identify the best model with the lowest error.</p>
<pre><code class="lang-r">val.errors
</code></pre>
<pre><code>##  [1] 220968.0 169157.1 178518.2 163426.1 168418.1 171270.6 162377.1
##  [8] 157909.3 154055.7 148162.1 151156.4 151742.5 152214.5 157358.7
## [15] 158541.4 158743.3 159972.7 159859.8 160105.6
</code></pre><pre><code class="lang-r">min.val.errors &lt;- which.min(val.errors)
coef(regfit.best, min.val.errors)
</code></pre>
<pre><code>## (Intercept)       AtBat        Hits       Walks      CAtBat       CHits 
## -80.2751499  -1.4683816   7.1625314   3.6430345  -0.1855698   1.1053238 
##      CHmRun      CWalks     LeagueN   DivisionW     PutOuts 
##   1.3844863  -0.7483170  84.5576103 -53.0289658   0.2381662
</code></pre><p>We can combine these steps into a function that can be called repeatedly when running k-fold cross-validation.</p>
<pre><code class="lang-r">predict.regsubsets &lt;- <span class="hljs-keyword">function</span>(object, newdata, id, <span class="hljs-keyword">...</span>) {
    form &lt;- as.formula(object$call[[<span class="hljs-number">2</span>]])
    mat &lt;- model.matrix(form, newdata)
    coefi &lt;- coef(object, id = id)
    xvars &lt;- names(coefi)
    mat[, xvars] %*% coefi
}
</code></pre>
<p>As a final step, we run <a href="http://bit.ly/R_regsubsets" target="_blank"><code>regsubsets()</code></a> on the full dataset and examine the coefficients associated with the model that has the lower validation error.</p>
<pre><code class="lang-r">regfit.best &lt;- regsubsets(Salary ~ ., data = Hitters, nvmax = <span class="hljs-number">19</span>)
coef(regfit.best, min.val.errors)
</code></pre>
<pre><code>##  (Intercept)        AtBat         Hits        Walks       CAtBat 
##  162.5354420   -2.1686501    6.9180175    5.7732246   -0.1300798 
##        CRuns         CRBI       CWalks    DivisionW      PutOuts 
##    1.4082490    0.7743122   -0.8308264 -112.3800575    0.2973726 
##      Assists 
##    0.2831680
</code></pre><p>For cross-validation, we create the number of folds needed (10, in this case) and allocate a matrix for storing the results.</p>
<pre><code class="lang-r">k &lt;- <span class="hljs-number">10</span>
set.seed(<span class="hljs-number">1</span>)
folds &lt;- sample(<span class="hljs-number">1</span>:k, nrow(Hitters), replace = <span class="hljs-literal">TRUE</span>)
cv.errors &lt;- matrix(<span class="hljs-literal">NA</span>, k, <span class="hljs-number">19</span>, dimnames = list(<span class="hljs-literal">NULL</span>, paste(<span class="hljs-number">1</span>:<span class="hljs-number">19</span>)))
</code></pre>
<p>We then run through each fold in a for loop and predict the salary using our predict function. We then calculate the validation error for each fold and save them in the matrix created above.</p>
<pre><code class="lang-r"><span class="hljs-keyword">for</span> (j <span class="hljs-keyword">in</span> <span class="hljs-number">1</span>:k) {
    best.fit &lt;- regsubsets(Salary ~ ., data = Hitters[folds != j, ], nvmax = <span class="hljs-number">19</span>)
    <span class="hljs-keyword">for</span> (i <span class="hljs-keyword">in</span> <span class="hljs-number">1</span>:<span class="hljs-number">19</span>) {
        pred &lt;- predict(best.fit, Hitters[folds == j, ], id = i)
        cv.errors[j, i] &lt;- mean((Hitters$Salary[folds == j] - pred)^<span class="hljs-number">2</span>)
    }
}
</code></pre>
<p>We calculate the mean error for all subsets by applying mean to each column using the <a href="http://bit.ly/R_apply" target="_blank"><code>apply()</code></a> function</p>
<pre><code class="lang-r">mean.cv.errors &lt;- apply(cv.errors, <span class="hljs-number">2</span>, mean)
mean.cv.errors
</code></pre>
<pre><code>##        1        2        3        4        5        6        7        8 
## 160093.5 140196.8 153117.0 151159.3 146841.3 138302.6 144346.2 130207.7 
##        9       10       11       12       13       14       15       16 
## 129459.6 125334.7 125153.8 128273.5 133461.0 133974.6 131825.7 131882.8 
##       17       18       19 
## 132750.9 133096.2 132804.7
</code></pre><pre><code class="lang-r">par(mfrow = c(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))
plot(mean.cv.errors, type = <span class="hljs-string">&quot;b&quot;</span>)
</code></pre>
<p><img src="lab_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-22-1.png" alt=""></p>
<p>Finally we run <a href="http://bit.ly/R_regsubsets" target="_blank"><code>regsubsets()</code></a> on the full dataset and show the coefficients for the best performing model.</p>
<pre><code class="lang-r">reg.best &lt;- regsubsets(Salary ~ ., data = Hitters, nvmax = <span class="hljs-number">19</span>)
coef(reg.best, which.min(mean.cv.errors))
</code></pre>
<pre><code>##  (Intercept)        AtBat         Hits        Walks       CAtBat 
##  135.7512195   -2.1277482    6.9236994    5.6202755   -0.1389914 
##        CRuns         CRBI       CWalks      LeagueN    DivisionW 
##    1.4553310    0.7852528   -0.8228559   43.1116152 -111.1460252 
##      PutOuts      Assists 
##    0.2894087    0.2688277
</code></pre><h2 id="6-6-lab-2-ridge-regression-and-the-lasso">6.6 Lab 2: Ridge Regression and the Lasso</h2>
<p>In order to run ridge regression, we first need to create a matrix from our dataset using the <a href="http://bit.ly/R_model_matrix" target="_blank"><code>model.matrix()</code></a> function.</p>
<pre><code class="lang-r">x &lt;- model.matrix(Salary ~ ., Hitters)[, -<span class="hljs-number">1</span>]
y &lt;- Hitters$Salary
</code></pre>
<h3 id="6-6-1-ridge-regression">6.6.1 Ridge Regression</h3>
<p>The <code>glmnet</code> package provides functionality to fit ridge regression and lasso models. We load the package and call <a href="http://bit.ly/R_glmnet" target="_blank"><code>glmnet()</code></a> to perform ridge regression.</p>
<pre><code class="lang-r"><span class="hljs-keyword">library</span>(glmnet)
</code></pre>
<pre><code>## Loading required package: Matrix
## Loading required package: foreach
## Loaded glmnet 2.0-2
</code></pre><pre><code class="lang-r">grid &lt;- <span class="hljs-number">10</span>^seq(<span class="hljs-number">10</span>, -<span class="hljs-number">2</span>, length = <span class="hljs-number">100</span>)
ridge.mod &lt;- glmnet(x, y, alpha = <span class="hljs-number">0</span>, lambda = grid)
</code></pre>
<pre><code class="lang-r">dim(coef(ridge.mod))
</code></pre>
<pre><code>## [1]  20 100
</code></pre><p>We can look at the coefficients at different values for (\lambda). Here we randomly choose two different values and notice that smaller values of (\lambda) result in larger coefficient estimates and vice-versa.</p>
<pre><code class="lang-r">ridge.mod$lambda[<span class="hljs-number">50</span>]
</code></pre>
<pre><code>## [1] 11497.57
</code></pre><pre><code class="lang-r">coef(ridge.mod)[, <span class="hljs-number">50</span>]
</code></pre>
<pre><code>##   (Intercept)         AtBat          Hits         HmRun          Runs 
## 407.356050200   0.036957182   0.138180344   0.524629976   0.230701523 
##           RBI         Walks         Years        CAtBat         CHits 
##   0.239841459   0.289618741   1.107702929   0.003131815   0.011653637 
##        CHmRun         CRuns          CRBI        CWalks       LeagueN 
##   0.087545670   0.023379882   0.024138320   0.025015421   0.085028114 
##     DivisionW       PutOuts       Assists        Errors    NewLeagueN 
##  -6.215440973   0.016482577   0.002612988  -0.020502690   0.301433531
</code></pre><pre><code class="lang-r">sqrt(sum(coef(ridge.mod)[-<span class="hljs-number">1</span>, <span class="hljs-number">50</span>]^<span class="hljs-number">2</span>))
</code></pre>
<pre><code>## [1] 6.360612
</code></pre><pre><code class="lang-r">ridge.mod$lambda[<span class="hljs-number">60</span>]
</code></pre>
<pre><code>## [1] 705.4802
</code></pre><pre><code class="lang-r">coef(ridge.mod)[, <span class="hljs-number">60</span>]
</code></pre>
<pre><code>##  (Intercept)        AtBat         Hits        HmRun         Runs 
##  54.32519950   0.11211115   0.65622409   1.17980910   0.93769713 
##          RBI        Walks        Years       CAtBat        CHits 
##   0.84718546   1.31987948   2.59640425   0.01083413   0.04674557 
##       CHmRun        CRuns         CRBI       CWalks      LeagueN 
##   0.33777318   0.09355528   0.09780402   0.07189612  13.68370191 
##    DivisionW      PutOuts      Assists       Errors   NewLeagueN 
## -54.65877750   0.11852289   0.01606037  -0.70358655   8.61181213
</code></pre><pre><code class="lang-r">sqrt(sum(coef(ridge.mod)[-<span class="hljs-number">1</span>, <span class="hljs-number">60</span>]^<span class="hljs-number">2</span>))
</code></pre>
<pre><code>## [1] 57.11001
</code></pre><p>We can get ridge regression coefficients for any value of (\lambda) using <code>predict</code>.</p>
<pre><code class="lang-r">predict(ridge.mod, s = <span class="hljs-number">50</span>, type = <span class="hljs-string">&quot;coefficients&quot;</span>)[<span class="hljs-number">1</span>:<span class="hljs-number">20</span>, ]
</code></pre>
<pre><code>##   (Intercept)         AtBat          Hits         HmRun          Runs 
##  4.876610e+01 -3.580999e-01  1.969359e+00 -1.278248e+00  1.145892e+00 
##           RBI         Walks         Years        CAtBat         CHits 
##  8.038292e-01  2.716186e+00 -6.218319e+00  5.447837e-03  1.064895e-01 
##        CHmRun         CRuns          CRBI        CWalks       LeagueN 
##  6.244860e-01  2.214985e-01  2.186914e-01 -1.500245e-01  4.592589e+01 
##     DivisionW       PutOuts       Assists        Errors    NewLeagueN 
## -1.182011e+02  2.502322e-01  1.215665e-01 -3.278600e+00 -9.496680e+00
</code></pre><p>Next, we can cross-validation on ridge regression by first splitting the dataset into training and test subsets.</p>
<pre><code class="lang-r">set.seed(<span class="hljs-number">1</span>)
train &lt;- sample(<span class="hljs-number">1</span>:nrow(x), nrow(x)/<span class="hljs-number">2</span>)
test &lt;- (-train)
y.test &lt;- y[test]
</code></pre>
<p>We estimate the parameters with <a href="http://bit.ly/R_glmnet" target="_blank"><code>glmnet()</code></a> over the training set and predict the values on the test set to calculate the validation error.</p>
<pre><code class="lang-r">ridge.mod &lt;- glmnet(x[train, ], y[train], alpha = <span class="hljs-number">0</span>, lambda = grid, thresh = <span class="hljs-number">1e-12</span>)
ridge.pred &lt;- predict(ridge.mod, s = <span class="hljs-number">4</span>, newx = x[test, ])
mean((ridge.pred - y.test)^<span class="hljs-number">2</span>)
</code></pre>
<pre><code>## [1] 101036.8
</code></pre><pre><code class="lang-r">mean((mean(y[train]) - y.test)^<span class="hljs-number">2</span>)
</code></pre>
<pre><code>## [1] 193253.1
</code></pre><p>In the previous example, we used a value for (\lambda = 4) when evaluating the model on the test set. We can use a large value for (lamba) and see the difference in mean error.</p>
<pre><code class="lang-r">ridge.pred &lt;- predict(ridge.mod, s = <span class="hljs-number">1e+10</span>, newx = x[test, ])
mean((ridge.pred - y.test)^<span class="hljs-number">2</span>)
</code></pre>
<pre><code>## [1] 193253.1
</code></pre><p>We can also compare the results with a least squares model where (\lambda = 0).</p>
<pre><code class="lang-r">ridge.pred &lt;- predict(ridge.mod, s = <span class="hljs-number">0</span>, newx = x[test, ], exact = <span class="hljs-literal">T</span>)
mean((ridge.pred - y.test)^<span class="hljs-number">2</span>)
</code></pre>
<pre><code>## [1] 114783.1
</code></pre><pre><code class="lang-r">lm(y ~ x, subset = train)
</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ x, subset = train)
## 
## Coefficients:
## (Intercept)       xAtBat        xHits       xHmRun        xRuns  
##   299.42849     -2.54027      8.36682     11.64512     -9.09923  
##        xRBI       xWalks       xYears      xCAtBat       xCHits  
##     2.44105      9.23440    -22.93673     -0.18154     -0.11598  
##     xCHmRun       xCRuns        xCRBI      xCWalks     xLeagueN  
##    -1.33888      3.32838      0.07536     -1.07841     59.76065  
##  xDivisionW     xPutOuts     xAssists      xErrors  xNewLeagueN  
##   -98.86233      0.34087      0.34165     -0.64207     -0.67442
</code></pre><pre><code class="lang-r">predict(ridge.mod, s = <span class="hljs-number">0</span>, exact = <span class="hljs-literal">T</span>, type = <span class="hljs-string">&quot;coefficients&quot;</span>)[<span class="hljs-number">1</span>:<span class="hljs-number">20</span>, ]
</code></pre>
<pre><code>##  (Intercept)        AtBat         Hits        HmRun         Runs 
## 299.42883596  -2.54014665   8.36611719  11.64400720  -9.09877719 
##          RBI        Walks        Years       CAtBat        CHits 
##   2.44152119   9.23403909 -22.93584442  -0.18160843  -0.11561496 
##       CHmRun        CRuns         CRBI       CWalks      LeagueN 
##  -1.33836534   3.32817777   0.07511771  -1.07828647  59.76529059 
##    DivisionW      PutOuts      Assists       Errors   NewLeagueN 
## -98.85996590   0.34086400   0.34165605  -0.64205839  -0.67606314
</code></pre><p>We can choose different values for (\lambda) by running cross-vaidation on ridge regression using <a href="http://bit.ly/R_cv_glmnet" target="_blank"><code>cv.glmnet()</code></a>.</p>
<pre><code class="lang-r">set.seed(<span class="hljs-number">1</span>)
cv.out &lt;- cv.glmnet(x[train, ], y[train], alpha = <span class="hljs-number">0</span>)
plot(cv.out)
</code></pre>
<p><img src="lab_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-35-1.png" alt=""></p>
<pre><code class="lang-r">bestlam &lt;- cv.out$lambda.min
bestlam
</code></pre>
<pre><code>## [1] 211.7416
</code></pre><p>The best performing model is the one with (\lambda = 211.74).</p>
<pre><code class="lang-r">ridge.pred &lt;- predict(ridge.mod, s = bestlam, newx = x[test, ])
mean((ridge.pred - y.test)^<span class="hljs-number">2</span>)
</code></pre>
<pre><code>## [1] 96015.51
</code></pre><p>Finally, we run ridge regression on the full dataset and examine the coefficients for the model with the best MSE.</p>
<pre><code class="lang-r">out &lt;- glmnet(x, y, alpha = <span class="hljs-number">0</span>)
predict(out, type = <span class="hljs-string">&quot;coefficients&quot;</span>, s = bestlam)[<span class="hljs-number">1</span>:<span class="hljs-number">20</span>, ]
</code></pre>
<pre><code>##  (Intercept)        AtBat         Hits        HmRun         Runs 
##   9.88487157   0.03143991   1.00882875   0.13927624   1.11320781 
##          RBI        Walks        Years       CAtBat        CHits 
##   0.87318990   1.80410229   0.13074381   0.01113978   0.06489843 
##       CHmRun        CRuns         CRBI       CWalks      LeagueN 
##   0.45158546   0.12900049   0.13737712   0.02908572  27.18227535 
##    DivisionW      PutOuts      Assists       Errors   NewLeagueN 
## -91.63411299   0.19149252   0.04254536  -1.81244470   7.21208390
</code></pre><h3 id="6-6-2-the-lasso">6.6.2 The Lasso</h3>
<p>The lasso model can be estimated in the same way as ridge regression. The <code>alpha = 1</code> parameter tells <a href="http://bit.ly/R_glmnet" target="_blank"><code>glmnet()</code></a> to run lasso regression instead of ridge regression.</p>
<pre><code class="lang-r">lasso.mod &lt;- glmnet(x[train, ], y[train], alpha = <span class="hljs-number">1</span>, lambda = grid)
plot(lasso.mod)
</code></pre>
<p><img src="lab_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-38-1.png" alt=""></p>
<p>Similarly, we can perform cross-validation using identical step as we did in the last exercise on ridge regression.</p>
<pre><code class="lang-r">set.seed(<span class="hljs-number">1</span>)
cv.out &lt;- cv.glmnet(x[train, ], y[train], alpha = <span class="hljs-number">1</span>)
plot(cv.out)
</code></pre>
<p><img src="lab_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-39-1.png" alt=""></p>
<pre><code class="lang-r">bestlam &lt;- cv.out$lambda.min
lasso.pred &lt;- predict(lasso.mod, s = bestlam, newx = x[test, ])
mean((lasso.pred - y.test)^<span class="hljs-number">2</span>)
</code></pre>
<pre><code>## [1] 100743.4
</code></pre><p>We can compare these results with ridge regression by examining the coefficient estimates.</p>
<pre><code class="lang-r">out &lt;- glmnet(x, y, alpha = <span class="hljs-number">1</span>, lambda = grid)
lasso.coef &lt;- predict(out, type = <span class="hljs-string">&quot;coefficients&quot;</span>, s = bestlam)[<span class="hljs-number">1</span>:<span class="hljs-number">20</span>, ]
lasso.coef
</code></pre>
<pre><code>##  (Intercept)        AtBat         Hits        HmRun         Runs 
##   18.5394844    0.0000000    1.8735390    0.0000000    0.0000000 
##          RBI        Walks        Years       CAtBat        CHits 
##    0.0000000    2.2178444    0.0000000    0.0000000    0.0000000 
##       CHmRun        CRuns         CRBI       CWalks      LeagueN 
##    0.0000000    0.2071252    0.4130132    0.0000000    3.2666677 
##    DivisionW      PutOuts      Assists       Errors   NewLeagueN 
## -103.4845458    0.2204284    0.0000000    0.0000000    0.0000000
</code></pre><pre><code class="lang-r">lasso.coef[lasso.coef != <span class="hljs-number">0</span>]
</code></pre>
<pre><code>##  (Intercept)         Hits        Walks        CRuns         CRBI 
##   18.5394844    1.8735390    2.2178444    0.2071252    0.4130132 
##      LeagueN    DivisionW      PutOuts 
##    3.2666677 -103.4845458    0.2204284
</code></pre><h2 id="6-7-lab-3-pcr-and-pls-regression">6.7 Lab 3: PCR and PLS Regression</h2>
<p>The <code>pls</code> package provides functions for performing Principal Components Regression (PCR) and Partial Least Squares (PLS)</p>
<h3 id="6-7-1-principal-components-regression">6.7.1 Principal Components Regression</h3>
<p>We start by loading the <code>pls</code> package and calling <a href="http://bit.ly/R_pcr" target="_blank"><code>pcr()</code></a> on the <code>Hitters</code> dataset. The <code>scale = TRUE</code> parameter is used to standardize each predictor by dividing it by its sample standard deviation. The <code>validation = &quot;CV&quot;</code> parameter tells <a href="http://bit.ly/R_pcr" target="_blank"><code>pcr()</code></a> to perform cross-validation.</p>
<pre><code class="lang-r"><span class="hljs-keyword">library</span>(pls)
</code></pre>
<pre><code>## 
## Attaching package: &apos;pls&apos;
## 
## The following object is masked from &apos;package:stats&apos;:
## 
##     loadings
</code></pre><pre><code class="lang-r">set.seed(<span class="hljs-number">2</span>)
pcr.fit &lt;- pcr(Salary ~ ., data = Hitters, scale = <span class="hljs-literal">TRUE</span>, validation = <span class="hljs-string">&quot;CV&quot;</span>)
</code></pre>
<pre><code class="lang-r">summary(pcr.fit)
</code></pre>
<pre><code>## Data:    X dimension: 263 19 
##  Y dimension: 263 1
## Fit method: svdpc
## Number of components considered: 19
## 
## VALIDATION: RMSEP
## Cross-validated using 10 random segments.
##        (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps
## CV             452    348.9    352.2    353.5    352.8    350.1    349.1
## adjCV          452    348.7    351.8    352.9    352.1    349.3    348.0
##        7 comps  8 comps  9 comps  10 comps  11 comps  12 comps  13 comps
## CV       349.6    350.9    352.9     353.8     355.0     356.2     363.5
## adjCV    348.5    349.8    351.6     352.3     353.4     354.5     361.6
##        14 comps  15 comps  16 comps  17 comps  18 comps  19 comps
## CV        355.2     357.4     347.6     350.1     349.2     352.6
## adjCV     352.8     355.2     345.5     347.6     346.7     349.8
## 
## TRAINING: % variance explained
##         1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps
## X         38.31    60.16    70.84    79.03    84.29    88.63    92.26
## Salary    40.63    41.58    42.17    43.22    44.90    46.48    46.69
##         8 comps  9 comps  10 comps  11 comps  12 comps  13 comps  14 comps
## X         94.96    96.28     97.26     97.98     98.65     99.15     99.47
## Salary    46.75    46.86     47.76     47.82     47.85     48.10     50.40
##         15 comps  16 comps  17 comps  18 comps  19 comps
## X          99.75     99.89     99.97     99.99    100.00
## Salary     50.55     53.01     53.85     54.61     54.61
</code></pre><p>We can plot the fitted model with <a href="http://bit.ly/R_validationplot" target="_blank"><code>validationplot()</code></a>.</p>
<pre><code class="lang-r">validationplot(pcr.fit, val.type = <span class="hljs-string">&quot;MSEP&quot;</span>)
</code></pre>
<p><img src="lab_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-43-1.png" alt=""></p>
<p>We can also perform PCR on a dataset split between training and test subsets. The syntax is identical to the previous exercise with the addition of a <code>subset</code> parameter indicating that the model should be estimated using only the training subset.</p>
<pre><code class="lang-r">set.seed(<span class="hljs-number">1</span>)
pcr.fit &lt;- pcr(Salary ~ ., data = Hitters, subset = train, scale = <span class="hljs-literal">TRUE</span>, validation = <span class="hljs-string">&quot;CV&quot;</span>)
validationplot(pcr.fit, val.type = <span class="hljs-string">&quot;MSEP&quot;</span>)
</code></pre>
<p><img src="lab_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-44-1.png" alt=""></p>
<p>We can calculate the MSE by predicting the <code>y</code> with a value for ncomp that results in the lowest cross-validation error.</p>
<pre><code class="lang-r">pcr.pred &lt;- predict(pcr.fit, x[test, ], ncomp = <span class="hljs-number">7</span>)
mean((pcr.pred - y.test)^<span class="hljs-number">2</span>)
</code></pre>
<pre><code>## [1] 96556.22
</code></pre><pre><code class="lang-r">pcr.fit &lt;- pcr(y ~ x, scale = <span class="hljs-literal">TRUE</span>, ncomp = <span class="hljs-number">7</span>)
summary(pcr.fit)
</code></pre>
<pre><code>## Data:    X dimension: 263 19 
##  Y dimension: 263 1
## Fit method: svdpc
## Number of components considered: 7
## TRAINING: % variance explained
##    1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps
## X    38.31    60.16    70.84    79.03    84.29    88.63    92.26
## y    40.63    41.58    42.17    43.22    44.90    46.48    46.69
</code></pre><h3 id="6-7-2-partial-least-squares">6.7.2 Partial Least Squares</h3>
<p>Partial Least Squares is also provided by the <code>pls</code> package, and has the same syntax as the <a href="http://bit.ly/R_pcr" target="_blank"><code>pcr()</code></a> function. We fit a PLS model using the <a href="http://bit.ly/R_pcr" target="_blank"><code>plsr()</code></a> function.</p>
<pre><code class="lang-r">set.seed(<span class="hljs-number">1</span>)
pls.fit &lt;- plsr(Salary ~ ., data = Hitters, subset = train, scale = <span class="hljs-literal">TRUE</span>, validation = <span class="hljs-string">&quot;CV&quot;</span>)
summary(pls.fit)
</code></pre>
<pre><code>## Data:    X dimension: 131 19 
##  Y dimension: 131 1
## Fit method: kernelpls
## Number of components considered: 19
## 
## VALIDATION: RMSEP
## Cross-validated using 10 random segments.
##        (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps
## CV           464.6    394.2    391.5    393.1    395.0    415.0    424.0
## adjCV        464.6    393.4    390.2    391.1    392.9    411.5    418.8
##        7 comps  8 comps  9 comps  10 comps  11 comps  12 comps  13 comps
## CV       424.5    415.8    404.6     407.1     412.0     414.4     410.3
## adjCV    418.9    411.4    400.7     402.2     407.2     409.3     405.6
##        14 comps  15 comps  16 comps  17 comps  18 comps  19 comps
## CV        406.2     408.6     410.5     408.8     407.8     410.2
## adjCV     401.8     403.9     405.6     404.1     403.2     405.5
## 
## TRAINING: % variance explained
##         1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps
## X         38.12    53.46    66.05    74.49    79.33    84.56    87.09
## Salary    33.58    38.96    41.57    42.43    44.04    45.59    47.05
##         8 comps  9 comps  10 comps  11 comps  12 comps  13 comps  14 comps
## X         90.74    92.55     93.94     97.23     97.88     98.35     98.85
## Salary    47.53    48.42     49.68     50.04     50.54     50.78     50.92
##         15 comps  16 comps  17 comps  18 comps  19 comps
## X          99.11     99.43     99.78     99.99    100.00
## Salary     51.04     51.11     51.15     51.16     51.18
</code></pre><pre><code class="lang-r">validationplot(pls.fit, val.type = <span class="hljs-string">&quot;MSEP&quot;</span>)
</code></pre>
<p><img src="lab_files/figure-markdown_github+backtick_code_blocks+autolink_bare_uris/unnamed-chunk-47-1.png" alt=""></p>
<p>We perform cross-valiation on the test set in the same way and determine that the lowest cross-validation error is obtained with 2 components.</p>
<pre><code class="lang-r">pls.pred &lt;- predict(pls.fit, x[test, ], ncomp = <span class="hljs-number">2</span>)
mean((pls.pred - y.test)^<span class="hljs-number">2</span>)
</code></pre>
<pre><code>## [1] 101417.5
</code></pre><p>We can now run PLS on the full dataset with 2 components and display the summary of the results.</p>
<pre><code class="lang-r">pls.fit &lt;- plsr(Salary ~ ., data = Hitters, scale = <span class="hljs-literal">TRUE</span>, ncomp = <span class="hljs-number">2</span>)
summary(pls.fit)
</code></pre>
<pre><code>## Data:    X dimension: 263 19 
##  Y dimension: 263 1
## Fit method: kernelpls
## Number of components considered: 2
## TRAINING: % variance explained
##         1 comps  2 comps
## X         38.08    51.03
## Salary    43.05    46.40
</code></pre>
                    
                    </section>
                
                
                </div>
            </div>
        </div>

        
        <a href="../chapter6/index.html" class="navigation navigation-prev " aria-label="Previous page: Chapter 6. Linear Model Selection and Regularization"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="../chapter6/solutions.html" class="navigation navigation-next " aria-label="Next page: Solutions"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="../gitbook/app.js"></script>

<script>
require(["gitbook"], function(gitbook) {
    var config = {"fontSettings":{"theme":null,"family":"sans","size":2}};
    gitbook.start(config);
});
</script>

        
    </body>
    
</html>
