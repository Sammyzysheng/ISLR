## 5.4 Exercises

```{r}
library(ISLR)
```

### Exercise 5
```{r}
library(boot)

set.seed(0)
Default <- na.omit(Default)

m0 <- glm(default ~ income + balance, data = Default, family = "binomial")
summary(m0)

validation_error_5b <- function() {
    # Predictors are income and balance
    
    # (i):
    n <- dim(Default)[1]
    training_samples <- sample(1:n, floor(n/2))
    validation_samples <- (1:n)[-training_samples]
    
    # (ii):
    m <- glm(default ~ income + balance, data = Default, family = "binomial", subset = training_samples)
    
    # Results from 'predict' are in terms of log odds or the logit tranformation of the probabilities
    predictions <- predict(m, newdata = Default[validation_samples, ])
    
    default <- factor(rep("No", length(validation_samples)), c("No", "Yes"))
    default[predictions > 0] <- factor("Yes", c("No", "Yes"))
    
    validation_error_rate <- mean(default != Default[validation_samples, ]$default)
}

v_error = validation_error_5b()

v_errors <- rep(0, 3)
for (i in 1:length(v_errors)) {
  v_errors[i] = validation_error_5b()
}
```

Validation set error is: `r v_error`.

Three more estimates of the validation set error would give: `r unlist(v_errors)`.

```{r}
validation_error_5d <- function() {
    # Predictors are income, balance, AND student
    
    # (i):
    n <- dim(Default)[1]
    training_samples <- sample(1:n, floor(n/2))
    validation_samples <- (1:n)[-training_samples]
    
    # (ii):
    m <- glm(default ~ income + balance + student, data = Default, family = "binomial", subset = training_samples)
    
    # Results from 'predict' are in terms of log odds or the logit tranformation of the probabilities
    predictions <- predict(m, newdata = Default[validation_samples, ])
    
    default <- factor(rep("No", length(validation_samples)), c("No", "Yes"))
    default[predictions > 0] <- factor("Yes", c("No", "Yes"))
    
    validation_error_rate <- mean(default != Default[validation_samples, ]$default)
}

v_error = validation_error_5d()
```

Using the predictor **student**, our validation set error is: `r v_error`.

### Exercise 6
```{r}
set.seed(0)

Default <- na.omit(Default)

# Estimate the base model (to get standard errors of the coefficients):
m0 <- glm(default ~ income + balance, data = Default, family = "binomial")
summary(m0)


boot.fn <- function(data, index) {
    m <- glm(default ~ income + balance, data = data[index, ], family = "binomial")
    return(coefficients(m))
}
boot.fn(Default, 1:10000)  # test our boot function

boot(Default, boot.fn, 1000)
```

### Exercise 7
```{r}
set.seed(0)

# Part (a):
m_0 <- glm(Direction ~ Lag1 + Lag2, data = Weekly, family = "binomial")

# Part (b):
m_loocv <- glm(Direction ~ Lag1 + Lag2, data = Weekly[-1, ], family = "binomial")

weekly_predict = predict(m_loocv, newdata = Weekly[1, ]) > 0
weekly_direction = Weekly[1, ]$Direction
```

Prediction on first sample is `r weekly_predict` (1=>Up; 0=>Down)

First samples true direction is `r weekly_direction`

```{r}
n <- dim(Weekly)[1]
number_of_errors <- 0
for (ii in 1:n) {
    m_loocv <- glm(Direction ~ Lag1 + Lag2, data = Weekly[-ii, ], family = "binomial")
    
    error_1 <- (predict(m_loocv, newdata = Weekly[ii, ]) > 0) & (Weekly[ii, ]$Direction == "Down")
    error_2 <- (predict(m_loocv, newdata = Weekly[ii, ]) < 0) & (Weekly[ii, ]$Direction == "Up")
    if (error_1 | error_2) {
        number_of_errors <- number_of_errors + 1
    }
}
LOOCV_test_error_rate = sprintf("%10.6f", number_of_errors/n)
```

LOOCV test error rate = `r LOOCV_test_error_rate`

### Exercise 8
```{r}
# Part (a):
set.seed(1)

x <- rnorm(100)
y <- x - 2 * x^2 + rnorm(100)

plot(x, y)
# dev.off()

DF <- data.frame(y = y, x = x)

# Do cross-validation on each model:
m_i <- glm(y ~ x, data = DF)
cv.err <- cv.glm(DF, m_i)
result = sprintf("%10.6f", cv.err$delta[1])
```

Model (i): cv output= `r result`

```{r}
m_ii <- glm(y ~ x + I(x^2), data = DF)
cv.err <- cv.glm(DF, m_ii)
result = sprintf("%10.6f", cv.err$delta[1])
```

Model (ii): cv output= `r result`


```{r}
m_iii <- glm(y ~ x + I(x^2) + I(x^3), data = DF)
cv.err <- cv.glm(DF, m_iii)
result = sprintf("%10.6f", cv.err$delta[1])
```

Model (iii): cv output= `r result`

```{r}
m_iv <- glm(y ~ x + I(x^2) + I(x^3) + I(x^4), data = DF)
cv.err <- cv.glm(DF, m_iv)
result = sprintf("%10.6f", cv.err$delta[1])
```

Model (iv): cv output= `r result`

### Exercise 9

```{r}
library(MASS)

Boston <- na.omit(Boston)

# Part (a):
mu_hat <- mean(Boston$medv)

# Part (b):
n <- dim(Boston)[1]
mu_se <- sd(Boston$medv)/sqrt(n)

mean_boot.fn <- function(data, index) {
    mean(data[index])
}

boot(Boston$medv, mean_boot.fn, 1000)

# Part (e):
median(Boston$medv)

median_boot.fn <- function(data, index) {
    median(data[index])
}

boot(Boston$medv, median_boot.fn, 1000)

# Part (g):
quantile(Boston$medv, probs = c(0.1))

ten_percent_boot.fn <- function(data, index) {
    quantile(data[index], probs = c(0.1))
}

boot(Boston$medv, ten_percent_boot.fn, 1000)
``` 

