## 8.4 Exercises

### Exercise 3
```{r}
p1 <- seq(0 + 1e-06, 1 - 1e-06, length.out = 100)
p2 <- 1 - p1

# The missclassification error-rate:
E <- 1 - apply(rbind(p1, p2), 2, max)

# The Gini index:
G <- p1 * (1 - p1) + p2 * (1 - p2)

# The cross-entropy:
D <- -(p1 * log(p1) + p2 * log(p2))

plot(p1, E, type = "l", col = "black", xlab = "p_1", ylab = "value of error metric", ylim = c(min(c(E, G, D)), max(E, G, D)))
lines(p1, G, col = "blue")
lines(p1, D, col = "green")
legend(0.2, 0.1, c("Classification error", "Gini index", "Cross entropy"), col = c("black", "blue", "green"), lty = c(1, 1))
grid()
```

### Exercise 7
```{r}
library(MASS)
library(randomForest)

set.seed(0)

n <- nrow(Boston)
p <- ncol(Boston) - 1  # one column is the response we are trying to model i.e. 'medv' 

train <- sample(1:n, n/2)
test <- (1:n)[-train]

ntree_to_test <- seq(from = 1, to = 500, by = 10)

# For a number of mtry values and a number of trees look at the test error rate:

# For mtry == p:
mse.bag <- rep(NA, length(ntree_to_test))
for (nti in 1:length(ntree_to_test)) {
    nt <- ntree_to_test[nti]
    
    # Grow a tree with 'nt' trees:
    boston.bag <- randomForest(medv ~ ., data = Boston, mtry = p, ntree = nt, importance = TRUE, subset = train)
    
    # Make predictions with this tree on the test dataset:
    y_hat <- predict(boston.bag, newdata = Boston[test, ])
    
    mse.bag[nti] <- mean((Boston[test, ]$medv - y_hat)^2)
}

# For mtry=p/2:
mse.p_over_two <- rep(NA, length(ntree_to_test))
for (nti in 1:length(ntree_to_test)) {
    nt <- ntree_to_test[nti]
    
    # Grow a tree with 'nt' trees:
    boston.bag <- randomForest(medv ~ ., data = Boston, mtry = p/2, ntree = nt, importance = TRUE, subset = train)
    
    # Make predictions with this tree on the test dataset:
    y_hat <- predict(boston.bag, newdata = Boston[test, ])
    
    mse.p_over_two[nti] <- mean((Boston[test, ]$medv - y_hat)^2)
}


# Run random forest with mtry=sqrt(p) and test on test set
mse.sqrt_p <- rep(NA, length(ntree_to_test))
for (nti in 1:length(ntree_to_test)) {
    nt <- ntree_to_test[nti]
    
    # Grow a tree with 'nt' trees:
    boston.bag <- randomForest(medv ~ ., data = Boston, mtry = p/2, ntree = nt, importance = TRUE, subset = train)
    
    # Make predictions with this tree on the test dataset:
    y_hat <- predict(boston.bag, newdata = Boston[test, ])
    
    mse.sqrt_p[nti] <- mean((Boston[test, ]$medv - y_hat)^2)
}

plot(ntree_to_test, mse.bag, xlab = "Number of Trees", ylab = "Test MSE", col = "red", type = "l")
lines(ntree_to_test, mse.p_over_two, xlab = "Number of Trees", ylab = "Test MSE", col = "blue", type = "l")
lines(ntree_to_test, mse.sqrt_p, xlab = "Number of Trees", ylab = "Test MSE", col = "green", type = "l")
grid()

```

### Exercise 8
```{r}
library(tree)
library(ISLR)
attach(Carseats)

set.seed(0)

n <- nrow(Carseats)
p <- ncol(Carseats) - 1  # remove the column we seek to predict i.e. Sales

# Part (a):
train <- sample(1:n, n/2)
test <- (1:n)[-train]

# Part (b):
rtree.carseats <- tree(Sales ~ ., data = Carseats[train, ])
summary(rtree.carseats)

plot(rtree.carseats)
text(rtree.carseats, pretty = 0)

print(rtree.carseats)

y_hat <- predict(rtree.carseats, newdata = Carseats[test, ])
test.MSE <- mean((y_hat - Carseats[test, ]$Sales)^2)
print(test.MSE)

# Part (c): Use cross-validation to determine the optimal of tree complexity:
cv.carseats <- cv.tree(rtree.carseats)
names(cv.carseats)

print(cv.carseats)

plot(cv.carseats$size, cv.carseats$dev, type = "b")  # plot the tree size

# Pick the size of the tree you want to prune to: It looks like k=6 is the smallest tree with an error close to the minimum.

prune.carseats <- prune.tree(rtree.carseats, best = 6)

plot(prune.carseats)
text(prune.carseats, pretty = 0)

# Predict the MSE using this tree:
y_hat <- predict(prune.carseats, newdata = Carseats[test, ])
prune.MSE <- mean((y_hat - Carseats[test, ]$Sales)^2)
print(prune.MSE)

# Part (d): Use bagging
carseats.bag <- randomForest(Sales ~ ., data = Carseats, mtry = p, ntree = 500, importance = TRUE, subset = train)
y_hat <- predict(carseats.bag, newdata = Carseats[test, ])
mse.bag <- mean((Carseats[test, ]$Sales - y_hat)^2)
print(mse.bag)

plot(carseats.bag)

ibag <- importance(carseats.bag)
print(ibag[order(ibag[, 1]), ])

# Part (e): Use random forests
carseats.rf <- randomForest(Sales ~ ., data = Carseats, ntree = 500, mtry = p/3, importance = TRUE, subset = train)
y_hat <- predict(carseats.rf, newdata = Carseats[test, ])
mse.rf <- mean((Carseats[test, ]$Sales - y_hat)^2)
print(mse.rf)

plot(carseats.rf)

irf <- importance(carseats.rf)
print(irf[order(irf[, 1]), ])
```

### Exercise 9
```{r}
set.seed(0)

n <- nrow(OJ)
p <- ncol(OJ) - 1  # remove the response Purchase

# Part (a):
train <- sample(1:n, 800)
test <- (1:n)[-train]

# Part (b):
tree.OJ <- tree(Purchase ~ ., data = OJ[train, ])
summary(tree.OJ)

print(tree.OJ)

plot(tree.OJ)
text(tree.OJ, pretty = 0)

y_hat <- predict(tree.OJ, newdata = OJ[test, ], type = "class")  # gives classification labels
CT <- table(y_hat, OJ[test, ]$Purchase)
print(CT)
print("original tree: classificaion error rate on the test dataset:")
print((CT[1, 2] + CT[2, 1])/sum(CT))

# Part (c): Use cross-validation to determine the optimal of tree complexity:
cv.OJ <- cv.tree(tree.OJ)

plot(cv.OJ$size, cv.OJ$dev, type = "b")

# Pick the size of the tree you want to prune to:

prune.OJ <- prune.tree(tree.OJ, best = 5)

plot(prune.OJ)
text(prune.OJ, pretty = 0)

# Compute training error rates:
y_hat <- predict(prune.OJ, newdata = OJ[train, ], type = "class")
CT <- table(y_hat, OJ[train, ]$Purchase)
print("pruned tree: classificaion error rate on the training dataset:")
print((CT[1, 2] + CT[2, 1])/sum(CT))

# Compute testing error rates:
y_hat <- predict(prune.OJ, newdata = OJ[test, ], type = "class")
CT <- table(y_hat, OJ[test, ]$Purchase)
print("pruned tree: classificaion error rate on the test dataset:")
print((CT[1, 2] + CT[2, 1])/sum(CT)) 
```

### Exercise 10
```{r}
library(gbm)
library(glmnet)

set.seed(0)

Hitters <- na.omit(Hitters)
Hitters$Salary <- log(Hitters$Salary)

n <- nrow(Hitters)
p <- ncol(Hitters) - 1  # one column is the response we are trying to model i.e. 'Salary' 

train <- 1:200
test <- 201:n

lambda_set <- seq(1e-04, 0.04, by = 0.001)

# 
training_set_mse <- rep(NA, length(lambda_set))
test_set_mse <- rep(NA, length(lambda_set))
for (lmi in 1:length(lambda_set)) {
    lm <- lambda_set[lmi]
    
    boost.hitters <- gbm(Salary ~ ., data = Hitters[train, ], distribution = "gaussian", n.trees = 1000, interaction.depth = 4, shrinkage = lm)
    
    y_hat <- predict(boost.hitters, newdata = Hitters[train, ], n.trees = 1000)
    training_set_mse[lmi] <- mean((y_hat - Hitters[train, ]$Salary)^2)
    
    y_hat <- predict(boost.hitters, newdata = Hitters[test, ], n.trees = 1000)
    test_set_mse[lmi] <- mean((y_hat - Hitters[test, ]$Salary)^2)
}

plot(lambda_set, training_set_mse, type = "b", pch = 19, col = "red", xlab = "Lambda Value", ylab = "MSE")
lines(lambda_set, test_set_mse, type = "b", pch = 19, col = "green", xlab = "Lambda Value", ylab = "Test Set MSE")
grid()

# Looks like the test MSE results are insensitive to the exact value of lambda as long as its small enough:
lm <- 0.01
boost.hitters <- gbm(Salary ~ ., data = Hitters[train, ], distribution = "gaussian", n.trees = 1000, interaction.depth = 4, shrinkage = lm)
y_hat <- predict(boost.hitters, newdata = Hitters[test, ], n.trees = 1000)
print("regression boosting test MSE:")
print(mean((y_hat - Hitters[test, ]$Salary)^2))

# Try linear regression:
m <- lm(Salary ~ ., data = Hitters[train, ])
y_hat <- predict(m, newdata = Hitters[test, ])
print("linear regression test MSE:")
print(mean((y_hat - Hitters[test, ]$Salary)^2))

# Try the lasso:
MM <- model.matrix(Salary ~ ., data = Hitters[train, ])
cv.out <- cv.glmnet(MM, Hitters[train, ]$Salary, alpha = 1)
bestlam <- cv.out$lambda.1se
print("lasso CV best value of lambda (one standard error)")
print(bestlam)

lasso.mod <- glmnet(MM, Hitters[train, ]$Salary, alpha = 1)

MM_test <- model.matrix(Salary ~ ., data = Hitters[test, ])
y_hat <- predict(lasso.mod, s = bestlam, newx = MM_test)
print("lasso regression test MSE:")
print(mean((y_hat - Hitters[test, ]$Salary)^2))

# Try ridge regression:
cv.out <- cv.glmnet(MM, Hitters[train, ]$Salary, alpha = 0)
plot(cv.out)
bestlam <- cv.out$lambda.1se
print("ridge CV best value of lambda (one standard error)")
print(bestlam)

ridge.mod <- glmnet(MM, Hitters[train, ]$Salary, alpha = 0)
Y_hat <- predict(ridge.mod, s = bestlam, newx = MM_test)
print("ridge regression test MSE:")
print(mean((y_hat - Hitters[test, ]$Salary)^2))

# What are the most important variables:
summary(boost.hitters)

# Try randomForests on the Hitters dataset (not asked for in the problem statement):
rf.hitters <- randomForest(Salary ~ ., data = Hitters, mtry = p/3, ntree = 1000, importance = TRUE, subset = train)
y_hat <- predict(rf.hitters, newdata = Hitters[test, ])
mse.rf <- mean((Hitters[test, ]$Salary - y_hat)^2)
print("randomForest test MSE:")
print(mse.rf)

# Try BAGGING on the Hitters dataset:
bag.hitters <- randomForest(Salary ~ ., data = Hitters, mtry = p, ntree = 1000, importance = TRUE, subset = train)
y_hat <- predict(bag.hitters, newdata = Hitters[test, ])
mse.bag <- mean((Hitters[test, ]$Salary - y_hat)^2)
print("Bagging test MSE:")
print(mse.bag) 
```

### Exercise 11
```{r}
set.seed(0)

Caravan <- na.omit(Caravan)

n <- nrow(Caravan)
p <- ncol(Caravan) - 1  # one column is the response we are trying to model i.e. 'Purchase' 

train <- 1:1000
test <- 1001:n

# Transform the response 'Purchase' to be in [0,1] as required by gbm:
PurchaseBinary <- rep(0, n)
PurchaseBinary[Caravan$Purchase == "Yes"] <- 1
Caravan$Purchase <- PurchaseBinary

# Some variables seem to be very noninformative (have zero variance as reported by gbm):
Caravan$PVRAAUT <- NULL
Caravan$AVRAAUT <- NULL

# Train a gbm:
lm <- 0.01
boost.caravan <- gbm(Purchase ~ ., data = Caravan[train, ], distribution = "bernoulli", n.trees = 1000, interaction.depth = 2, shrinkage = lm)
summary(boost.caravan)

# Predict the testing error:
y_hat <- predict(boost.caravan, newdata = Caravan[test, ], n.trees = 1000)
p_hat <- exp(y_hat)/(1 + exp(y_hat))  # convert the logodd output into probabilities 

will_buy <- rep(0, length(test))
will_buy[p_hat > 0.2] <- 1

# Create a confusion matrix:
table(will_buy, Caravan[test, ]$Purchase)

# Train a logistic regression:
lr_model <- glm(Purchase ~ ., data = Caravan[train, ], family = "binomial")
y_hat <- predict(lr_model, newdata = Caravan[test, ])
p_hat <- exp(y_hat)/(1 + exp(y_hat))  # convert the logodd output into probabilities 

will_buy <- rep(0, length(test))
will_buy[p_hat > 0.2] <- 1

# Create a confusion matrix:
table(will_buy, Caravan[test, ]$Purchase)

```

